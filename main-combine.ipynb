{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 style=\"font-weight: bold;\">\n",
    "    Binary Classification from Tabular Data</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deskripsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan clustering sebagai salah satu metode feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from class_reg_preprocessing import (\n",
    "    FeatureOutliersHandling,\n",
    "    FeatureImputer,\n",
    "    FeatureResampling,\n",
    "    FeatureLabelEncoder,\n",
    "    FeatureDiscretizer,\n",
    "    FeatureRareCategoriesGrouping,\n",
    "    FeaturePolynomialAdder,\n",
    "    FeaturePowerTransformer,\n",
    "    FeatureGroupingNumeric,\n",
    "    FeatureDimensionReducer,\n",
    "    FeatureEncoder,\n",
    "    FeatureScaler,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_date</th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/1/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/2/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/3/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/4/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/5/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>3/31/2021 0:00</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4/1/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>4/2/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>4/3/2021 0:00</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>4/4/2021 0:00</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4048 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           read_date  interval_1  interval_2  interval_3  interval_4  \\\n",
       "0           3/1/2021      0.0625      0.0500      0.0687      0.0750   \n",
       "1           3/2/2021      0.0625      0.0500      0.0687      0.0625   \n",
       "2           3/3/2021      0.0625      0.0687      0.0500      0.0562   \n",
       "3           3/4/2021      0.0625      0.0625      0.0687      0.0500   \n",
       "4           3/5/2021      0.0625      0.0625      0.0500      0.0625   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "4043  3/31/2021 0:00      0.2125      0.2000      0.1625      0.1750   \n",
       "4044   4/1/2021 0:00      0.1625      0.1625      0.1500      0.1500   \n",
       "4045   4/2/2021 0:00      0.1625      0.2000      0.2125      0.1625   \n",
       "4046   4/3/2021 0:00      0.2250      0.2250      0.1625      0.1750   \n",
       "4047   4/4/2021 0:00      0.2000      0.1625      0.1625      0.2000   \n",
       "\n",
       "      interval_5  interval_6  interval_7  interval_8  interval_9  ...  \\\n",
       "0         0.0687      0.0500      0.0625      0.0687      0.0687  ...   \n",
       "1         0.0625      0.0562      0.0562      0.0625      0.0687  ...   \n",
       "2         0.0687      0.0625      0.0625      0.0625      0.0500  ...   \n",
       "3         0.0562      0.0625      0.0625      0.0625      0.0562  ...   \n",
       "4         0.0687      0.0625      0.0687      0.0562      0.0500  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "4043      0.2375      0.2125      0.1875      0.1750      0.2000  ...   \n",
       "4044      0.2000      0.1750      0.1625      0.1625      0.1500  ...   \n",
       "4045      0.1625      0.1375      0.1500      0.1250      0.1875  ...   \n",
       "4046      0.1750      0.1500      0.1500      0.2125      0.1625  ...   \n",
       "4047      0.1500      0.1500      0.1750      0.1750      0.1375  ...   \n",
       "\n",
       "      interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "0          0.0812       0.0687       0.0687       0.0562       0.0562   \n",
       "1          0.1375       0.0750       0.0687       0.0625       0.0625   \n",
       "2          0.1875       0.1062       0.0750       0.0687       0.0687   \n",
       "3          0.1125       0.0875       0.0687       0.0625       0.0562   \n",
       "4          0.0812       0.0562       0.0687       0.0625       0.0625   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4043       0.3375       0.3875       0.3375       0.3875       0.2500   \n",
       "4044       0.2375       0.2000       0.2125       0.2000       0.2000   \n",
       "4045       0.2500       0.2750       0.3750       0.3375       0.3250   \n",
       "4046       0.3375       0.4000       0.3500       0.2625       0.4000   \n",
       "4047       0.5250       0.4125       0.4000       0.4500       0.3625   \n",
       "\n",
       "      interval_46  interval_47  interval_48  id  label  \n",
       "0          0.0687       0.0687       0.0625   1      1  \n",
       "1          0.0562       0.0625       0.0625   1      1  \n",
       "2          0.0625       0.0562       0.0562   1      1  \n",
       "3          0.0625       0.0625       0.0687   1      1  \n",
       "4          0.0625       0.0562       0.0500   1      1  \n",
       "...           ...          ...          ...  ..    ...  \n",
       "4043       0.5125       0.4750       0.2000  57      0  \n",
       "4044       0.2875       0.1875       0.2250  57      0  \n",
       "4045       0.2625       0.3000       0.3500  57      0  \n",
       "4046       0.3375       0.8375       0.6625  57      0  \n",
       "4047       0.6500       1.3500       0.7875  57      0  \n",
       "\n",
       "[4048 rows x 51 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: define initial dataframes\n",
    "initial_df = pd.read_csv(f'{data_path}/EV_data.csv')\n",
    "# -----------------------------------\n",
    "\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: define test dataframe\n",
    "# test_features_df = pd.read_csv(f'{data_path}/test_features.csv')\n",
    "\n",
    "# submisssion_ids = test_features_df['ID']\n",
    "\n",
    "# test_features_df = test_features_df.drop(columns=['ID'])\n",
    "# # -------------------------------------\n",
    "\n",
    "# test_features_df = test_features_df.reindex(sorted(test_features_df.columns), axis=1)\n",
    "\n",
    "# test_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Target and Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define which columns are target labels\n",
    "label = 'label'\n",
    "# -----------------------------------\n",
    "# TODO: define which columns are categorical and which are numerical features\n",
    "categorical_features = ['id']\n",
    "\n",
    "# get all columns with float64 and int64 data types\n",
    "numerical_features = initial_df.select_dtypes(include=['float64']).columns\n",
    "# -----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Unnecessary Columns [TENTATIVE]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define columns to drop\n",
    "columns_to_drop = ['label', 'read_date']\n",
    "# -----------------------------------\n",
    "\n",
    "categorical_features = [col for col in categorical_features if col not in columns_to_drop]\n",
    "numerical_features = [col for col in numerical_features if col not in columns_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for initial data before removing duplicates: 4048\n",
      "Row count for initial data after removing duplicates: 4048\n"
     ]
    }
   ],
   "source": [
    "print('Row count for initial data before removing duplicates:', len(initial_df))\n",
    "initial_df.drop_duplicates(inplace=True)\n",
    "print('Row count for initial data after removing duplicates:', len(initial_df))\n",
    "initial_df.reset_index(drop=True, inplace=True) # Reset the index after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df.drop(columns=columns_to_drop)\n",
    "# test_features_df = test_features_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Wrong Value to NaN [Tentative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_values = '5'\n",
    "\n",
    "# initial_df['pendidikan'] = initial_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# initial_df['status_pernikahan'] = initial_df['status_pernikahan'].replace(wrong_values, np.nan)\n",
    "\n",
    "# test_features_df['pendidikan'] = test_features_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# test_features_df['status_pernikahan'] = test_features_df['status_pernikahan'].replace(wrong_values, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check Similarity Columns between Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_cols(df1: pd.DataFrame, df2: pd.DataFrame, label: str):\n",
    "    \"\"\"\n",
    "    Function to check if two DataFrames have the same columns, excluding the label column if it exists.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1: First DataFrame\n",
    "    - df2: Second DataFrame\n",
    "    - label: The name of the label column to exclude from the comparison (default is 'label').\n",
    "    \n",
    "    Returns:\n",
    "    - Boolean value indicating whether the columns are the same, excluding the label column\n",
    "    \"\"\"\n",
    "    # Exclude the label column if it exists in either DataFrame\n",
    "    df1_cols = df1.columns.drop(label) if label in df1.columns else df1.columns\n",
    "    df2_cols = df2.columns.drop(label) if label in df2.columns else df2.columns\n",
    "\n",
    "    # Compare the remaining columns\n",
    "    return df1_cols.equals(df2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Initial and test features have the same columns:', is_same_cols(initial_df, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grouping by ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = initial_df.groupby(['id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88 entries, 1 to 88\n",
      "Data columns (total 48 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   interval_1   88 non-null     float64\n",
      " 1   interval_2   88 non-null     float64\n",
      " 2   interval_3   88 non-null     float64\n",
      " 3   interval_4   88 non-null     float64\n",
      " 4   interval_5   88 non-null     float64\n",
      " 5   interval_6   88 non-null     float64\n",
      " 6   interval_7   88 non-null     float64\n",
      " 7   interval_8   88 non-null     float64\n",
      " 8   interval_9   88 non-null     float64\n",
      " 9   interval_10  88 non-null     float64\n",
      " 10  interval_11  88 non-null     float64\n",
      " 11  interval_12  88 non-null     float64\n",
      " 12  interval_13  88 non-null     float64\n",
      " 13  interval_14  88 non-null     float64\n",
      " 14  interval_15  88 non-null     float64\n",
      " 15  interval_16  88 non-null     float64\n",
      " 16  interval_17  88 non-null     float64\n",
      " 17  interval_18  88 non-null     float64\n",
      " 18  interval_19  88 non-null     float64\n",
      " 19  interval_20  88 non-null     float64\n",
      " 20  interval_21  88 non-null     float64\n",
      " 21  interval_22  88 non-null     float64\n",
      " 22  interval_23  88 non-null     float64\n",
      " 23  interval_24  88 non-null     float64\n",
      " 24  interval_25  88 non-null     float64\n",
      " 25  interval_26  88 non-null     float64\n",
      " 26  interval_27  88 non-null     float64\n",
      " 27  interval_28  88 non-null     float64\n",
      " 28  interval_29  88 non-null     float64\n",
      " 29  interval_30  88 non-null     float64\n",
      " 30  interval_31  88 non-null     float64\n",
      " 31  interval_32  88 non-null     float64\n",
      " 32  interval_33  88 non-null     float64\n",
      " 33  interval_34  88 non-null     float64\n",
      " 34  interval_35  88 non-null     float64\n",
      " 35  interval_36  88 non-null     float64\n",
      " 36  interval_37  88 non-null     float64\n",
      " 37  interval_38  88 non-null     float64\n",
      " 38  interval_39  88 non-null     float64\n",
      " 39  interval_40  88 non-null     float64\n",
      " 40  interval_41  88 non-null     float64\n",
      " 41  interval_42  88 non-null     float64\n",
      " 42  interval_43  88 non-null     float64\n",
      " 43  interval_44  88 non-null     float64\n",
      " 44  interval_45  88 non-null     float64\n",
      " 45  interval_46  88 non-null     float64\n",
      " 46  interval_47  88 non-null     float64\n",
      " 47  interval_48  88 non-null     float64\n",
      "dtypes: float64(48)\n",
      "memory usage: 33.7 KB\n"
     ]
    }
   ],
   "source": [
    "grouped_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, K=3, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        # list of sample indices for each cluster\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "\n",
    "        # the centers (mean vector) for each cluster\n",
    "        self.centroids = []\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # initialize\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        # optimize clusters\n",
    "        for _ in range(self.max_iters):\n",
    "            # assign samples to closest centroids (create clusters)\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            # calculate new centroids from the clusters\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "        # classify samples as the index of their clusters\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        # each sample will get the label of the cluster it was assigned to\n",
    "        labels = np.empty(self.n_samples)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_idx in cluster:\n",
    "                labels[sample_idx] = cluster_idx\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        # assign the samples to the closest centroids\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        # distance of the current sample to each centroid\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return closest_idx\n",
    "\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        # assign mean value of clusters to centroids\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "            centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids):\n",
    "        # distances between old and new centroids, for all centroids\n",
    "        distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)]\n",
    "        return sum(distances) == 0\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        for i, index in enumerate(self.clusters):\n",
    "            point = self.X[index].T\n",
    "            ax.scatter(*point)\n",
    "\n",
    "        for point in self.centroids:\n",
    "            ax.scatter(*point, marker=\"x\", color=\"black\", linewidth=2)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def elbow_method(df, max_k=10):\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    \n",
    "    # Calculate SSE for different values of k\n",
    "    sse = []\n",
    "    K = range(1, max_k+1)\n",
    "    \n",
    "    for k in K:\n",
    "        kmeans = KMeans(K=k, max_iters=100, plot_steps=False)\n",
    "        labels = kmeans.predict(scaled_features)\n",
    "        \n",
    "        # Calculate SSE\n",
    "        current_sse = 0\n",
    "        for i, cluster in enumerate(kmeans.clusters):\n",
    "            if len(cluster) > 0:  # Check if cluster is not empty\n",
    "                cluster_points = scaled_features[cluster]\n",
    "                centroid = kmeans.centroids[i]\n",
    "                current_sse += np.sum((cluster_points - centroid) ** 2)\n",
    "        \n",
    "        sse.append(current_sse)\n",
    "    \n",
    "    # Plot the elbow curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(K, sse, 'bx-')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "    plt.title('Elbow Method Using SSE')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return sse\n",
    "\n",
    "# Usage example:\n",
    "# Assuming initial_df is your pandas DataFrame\n",
    "sse_values = elbow_method(grouped_df, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans_clustering(df, n_clusters):\n",
    "    \"\"\"\n",
    "    Apply KMeans clustering to the DataFrame and return the original data\n",
    "    with cluster assignments added as a new column\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame\n",
    "    df_with_clusters = df.copy()\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    \n",
    "    # Apply KMeans clustering\n",
    "    kmeans = KMeans(K=n_clusters, max_iters=100, plot_steps=False)\n",
    "    cluster_labels = kmeans.predict(scaled_features)\n",
    "    \n",
    "    # Add cluster assignments to the DataFrame\n",
    "    df_with_clusters['cluster'] = cluster_labels\n",
    "    \n",
    "    # Add the centroids to a new DataFrame\n",
    "    centroid_values = scaler.inverse_transform(kmeans.centroids)\n",
    "    centroids_df = pd.DataFrame(\n",
    "        centroid_values,\n",
    "        columns=df.columns,\n",
    "        index=[f'Cluster_{i}' for i in range(n_clusters)]\n",
    "    )\n",
    "    \n",
    "    return df_with_clusters, centroids_df, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3  # Replace with your optimal number from the elbow method\n",
    "df_clustered, centroids, model = apply_kmeans_clustering(grouped_df, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>interval_10</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_40</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357178</td>\n",
       "      <td>0.328778</td>\n",
       "      <td>0.167091</td>\n",
       "      <td>0.146717</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.148480</td>\n",
       "      <td>0.148617</td>\n",
       "      <td>0.146985</td>\n",
       "      <td>0.097946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145767</td>\n",
       "      <td>0.308674</td>\n",
       "      <td>0.280676</td>\n",
       "      <td>0.447120</td>\n",
       "      <td>0.427693</td>\n",
       "      <td>0.420761</td>\n",
       "      <td>0.421170</td>\n",
       "      <td>0.398348</td>\n",
       "      <td>0.397659</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.931628</td>\n",
       "      <td>0.780407</td>\n",
       "      <td>0.701607</td>\n",
       "      <td>0.587072</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>0.347533</td>\n",
       "      <td>0.226337</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.116554</td>\n",
       "      <td>0.118050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302152</td>\n",
       "      <td>0.280278</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.271035</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.901472</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.624157</td>\n",
       "      <td>0.633398</td>\n",
       "      <td>0.628098</td>\n",
       "      <td>0.621033</td>\n",
       "      <td>0.582048</td>\n",
       "      <td>0.544943</td>\n",
       "      <td>0.530141</td>\n",
       "      <td>0.471989</td>\n",
       "      <td>0.403635</td>\n",
       "      <td>0.351878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.807307</td>\n",
       "      <td>0.792509</td>\n",
       "      <td>0.769272</td>\n",
       "      <td>0.737748</td>\n",
       "      <td>0.796576</td>\n",
       "      <td>0.727561</td>\n",
       "      <td>0.608802</td>\n",
       "      <td>0.557446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.367772</td>\n",
       "      <td>0.401193</td>\n",
       "      <td>0.398485</td>\n",
       "      <td>0.398617</td>\n",
       "      <td>0.338289</td>\n",
       "      <td>0.298198</td>\n",
       "      <td>0.239520</td>\n",
       "      <td>0.239241</td>\n",
       "      <td>0.246991</td>\n",
       "      <td>0.241822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499426</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.676065</td>\n",
       "      <td>0.690196</td>\n",
       "      <td>0.672387</td>\n",
       "      <td>0.625657</td>\n",
       "      <td>0.464509</td>\n",
       "      <td>0.381902</td>\n",
       "      <td>0.412065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.139646</td>\n",
       "      <td>0.142496</td>\n",
       "      <td>0.140054</td>\n",
       "      <td>0.131641</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.135709</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.134491</td>\n",
       "      <td>0.133946</td>\n",
       "      <td>0.128504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313426</td>\n",
       "      <td>0.319811</td>\n",
       "      <td>0.319135</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>0.204322</td>\n",
       "      <td>0.186928</td>\n",
       "      <td>0.163563</td>\n",
       "      <td>0.150385</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.151067</td>\n",
       "      <td>0.131902</td>\n",
       "      <td>0.129867</td>\n",
       "      <td>0.115604</td>\n",
       "      <td>0.120496</td>\n",
       "      <td>0.121446</td>\n",
       "      <td>0.115470</td>\n",
       "      <td>0.120224</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>0.135843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353367</td>\n",
       "      <td>0.354461</td>\n",
       "      <td>0.371309</td>\n",
       "      <td>0.355409</td>\n",
       "      <td>0.331772</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.148207</td>\n",
       "      <td>0.131774</td>\n",
       "      <td>0.138420</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.065565</td>\n",
       "      <td>0.074696</td>\n",
       "      <td>0.072761</td>\n",
       "      <td>0.076957</td>\n",
       "      <td>0.063130</td>\n",
       "      <td>0.072152</td>\n",
       "      <td>0.066196</td>\n",
       "      <td>0.074217</td>\n",
       "      <td>0.061957</td>\n",
       "      <td>0.061348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.127674</td>\n",
       "      <td>0.116826</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.149761</td>\n",
       "      <td>0.097848</td>\n",
       "      <td>0.079739</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>0.066717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.527413</td>\n",
       "      <td>0.519674</td>\n",
       "      <td>0.505435</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.652348</td>\n",
       "      <td>0.568870</td>\n",
       "      <td>0.681022</td>\n",
       "      <td>0.618652</td>\n",
       "      <td>0.632543</td>\n",
       "      <td>0.503826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584239</td>\n",
       "      <td>0.538174</td>\n",
       "      <td>0.469870</td>\n",
       "      <td>0.498891</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.540804</td>\n",
       "      <td>0.542739</td>\n",
       "      <td>0.540413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.249702</td>\n",
       "      <td>0.235302</td>\n",
       "      <td>0.226196</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.220626</td>\n",
       "      <td>0.218320</td>\n",
       "      <td>0.214380</td>\n",
       "      <td>0.215465</td>\n",
       "      <td>0.215461</td>\n",
       "      <td>0.234485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422122</td>\n",
       "      <td>0.440598</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.365196</td>\n",
       "      <td>0.382037</td>\n",
       "      <td>0.375515</td>\n",
       "      <td>0.381220</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.307717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.105043</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.108043</td>\n",
       "      <td>0.107457</td>\n",
       "      <td>0.109217</td>\n",
       "      <td>0.113957</td>\n",
       "      <td>0.112261</td>\n",
       "      <td>0.110783</td>\n",
       "      <td>0.124304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>0.138326</td>\n",
       "      <td>0.143109</td>\n",
       "      <td>0.123326</td>\n",
       "      <td>0.118152</td>\n",
       "      <td>0.111326</td>\n",
       "      <td>0.123848</td>\n",
       "      <td>0.113609</td>\n",
       "      <td>0.097609</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    interval_1  interval_2  interval_3  interval_4  interval_5  interval_6  \\\n",
       "id                                                                           \n",
       "1     0.357178    0.328778    0.167091    0.146717    0.146033    0.143589   \n",
       "2     0.931628    0.780407    0.701607    0.587072    0.419270    0.347533   \n",
       "3     0.624157    0.633398    0.628098    0.621033    0.582048    0.544943   \n",
       "4     0.367772    0.401193    0.398485    0.398617    0.338289    0.298198   \n",
       "5     0.139646    0.142496    0.140054    0.131641    0.134761    0.135709   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "84    0.151067    0.131902    0.129867    0.115604    0.120496    0.121446   \n",
       "85    0.065565    0.074696    0.072761    0.076957    0.063130    0.072152   \n",
       "86    0.527413    0.519674    0.505435    0.595500    0.652348    0.568870   \n",
       "87    0.249702    0.235302    0.226196    0.219943    0.220626    0.218320   \n",
       "88    0.105043    0.104261    0.108761    0.108043    0.107457    0.109217   \n",
       "\n",
       "    interval_7  interval_8  interval_9  interval_10  ...  interval_40  \\\n",
       "id                                                   ...                \n",
       "1     0.148480    0.148617    0.146985     0.097946  ...     0.145767   \n",
       "2     0.226337    0.131765    0.116554     0.118050  ...     0.302152   \n",
       "3     0.530141    0.471989    0.403635     0.351878  ...     0.686526   \n",
       "4     0.239520    0.239241    0.246991     0.241822  ...     0.499426   \n",
       "5     0.129870    0.134491    0.133946     0.128504  ...     0.313426   \n",
       "..         ...         ...         ...          ...  ...          ...   \n",
       "84    0.115470    0.120224    0.113020     0.135843  ...     0.353367   \n",
       "85    0.066196    0.074217    0.061957     0.061348  ...     0.129065   \n",
       "86    0.681022    0.618652    0.632543     0.503826  ...     0.584239   \n",
       "87    0.214380    0.215465    0.215461     0.234485  ...     0.422122   \n",
       "88    0.113957    0.112261    0.110783     0.124304  ...     0.132283   \n",
       "\n",
       "    interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "id                                                                    \n",
       "1      0.308674     0.280676     0.447120     0.427693     0.420761   \n",
       "2      0.280278     0.272800     0.271035     0.253641     0.543993   \n",
       "3      0.807307     0.792509     0.769272     0.737748     0.796576   \n",
       "4      0.543993     0.676065     0.690196     0.672387     0.625657   \n",
       "5      0.319811     0.319135     0.281502     0.238013     0.204322   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "84     0.354461     0.371309     0.355409     0.331772     0.228100   \n",
       "85     0.127674     0.116826     0.177370     0.149761     0.097848   \n",
       "86     0.538174     0.469870     0.498891     0.524000     0.544304   \n",
       "87     0.440598     0.443998     0.365196     0.382037     0.375515   \n",
       "88     0.138326     0.143109     0.123326     0.118152     0.111326   \n",
       "\n",
       "    interval_46  interval_47  interval_48  cluster  \n",
       "id                                                  \n",
       "1      0.421170     0.398348     0.397659      1.0  \n",
       "2      0.817770     0.901472     0.997396      0.0  \n",
       "3      0.727561     0.608802     0.557446      0.0  \n",
       "4      0.464509     0.381902     0.412065      0.0  \n",
       "5      0.186928     0.163563     0.150385      1.0  \n",
       "..          ...          ...          ...      ...  \n",
       "84     0.148207     0.131774     0.138420      1.0  \n",
       "85     0.079739     0.070326     0.066717      1.0  \n",
       "86     0.540804     0.542739     0.540413      0.0  \n",
       "87     0.381220     0.347800     0.307717      0.0  \n",
       "88     0.123848     0.113609     0.097609      1.0  \n",
       "\n",
       "[88 rows x 49 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save clustered data to csv\n",
    "df_clustered.to_csv(f'{data_path}/clustered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(f'{data_path}/clustered_data.csv')\n",
    "\n",
    "initial_df = initial_df.merge(\n",
    "    df2[['id', 'cluster']], \n",
    "    on='id', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>interval_10</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4048 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      interval_1  interval_2  interval_3  interval_4  interval_5  interval_6  \\\n",
       "0         0.0625      0.0500      0.0687      0.0750      0.0687      0.0500   \n",
       "1         0.0625      0.0500      0.0687      0.0625      0.0625      0.0562   \n",
       "2         0.0625      0.0687      0.0500      0.0562      0.0687      0.0625   \n",
       "3         0.0625      0.0625      0.0687      0.0500      0.0562      0.0625   \n",
       "4         0.0625      0.0625      0.0500      0.0625      0.0687      0.0625   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "4043      0.2125      0.2000      0.1625      0.1750      0.2375      0.2125   \n",
       "4044      0.1625      0.1625      0.1500      0.1500      0.2000      0.1750   \n",
       "4045      0.1625      0.2000      0.2125      0.1625      0.1625      0.1375   \n",
       "4046      0.2250      0.2250      0.1625      0.1750      0.1750      0.1500   \n",
       "4047      0.2000      0.1625      0.1625      0.2000      0.1500      0.1500   \n",
       "\n",
       "      interval_7  interval_8  interval_9  interval_10  ...  interval_41  \\\n",
       "0         0.0625      0.0687      0.0687       0.0500  ...       0.0812   \n",
       "1         0.0562      0.0625      0.0687       0.0625  ...       0.1375   \n",
       "2         0.0625      0.0625      0.0500       0.0625  ...       0.1875   \n",
       "3         0.0625      0.0625      0.0562       0.0500  ...       0.1125   \n",
       "4         0.0687      0.0562      0.0500       0.0625  ...       0.0812   \n",
       "...          ...         ...         ...          ...  ...          ...   \n",
       "4043      0.1875      0.1750      0.2000       0.1500  ...       0.3375   \n",
       "4044      0.1625      0.1625      0.1500       0.1625  ...       0.2375   \n",
       "4045      0.1500      0.1250      0.1875       0.1125  ...       0.2500   \n",
       "4046      0.1500      0.2125      0.1625       0.1750  ...       0.3375   \n",
       "4047      0.1750      0.1750      0.1375       0.1750  ...       0.5250   \n",
       "\n",
       "      interval_42  interval_43  interval_44  interval_45  interval_46  \\\n",
       "0          0.0687       0.0687       0.0562       0.0562       0.0687   \n",
       "1          0.0750       0.0687       0.0625       0.0625       0.0562   \n",
       "2          0.1062       0.0750       0.0687       0.0687       0.0625   \n",
       "3          0.0875       0.0687       0.0625       0.0562       0.0625   \n",
       "4          0.0562       0.0687       0.0625       0.0625       0.0625   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4043       0.3875       0.3375       0.3875       0.2500       0.5125   \n",
       "4044       0.2000       0.2125       0.2000       0.2000       0.2875   \n",
       "4045       0.2750       0.3750       0.3375       0.3250       0.2625   \n",
       "4046       0.4000       0.3500       0.2625       0.4000       0.3375   \n",
       "4047       0.4125       0.4000       0.4500       0.3625       0.6500   \n",
       "\n",
       "      interval_47  interval_48  id  cluster  \n",
       "0          0.0687       0.0625   1      1.0  \n",
       "1          0.0625       0.0625   1      1.0  \n",
       "2          0.0562       0.0562   1      1.0  \n",
       "3          0.0625       0.0687   1      1.0  \n",
       "4          0.0562       0.0500   1      1.0  \n",
       "...           ...          ...  ..      ...  \n",
       "4043       0.4750       0.2000  57      0.0  \n",
       "4044       0.1875       0.2250  57      0.0  \n",
       "4045       0.3000       0.3500  57      0.0  \n",
       "4046       0.8375       0.6625  57      0.0  \n",
       "4047       1.3500       0.7875  57      0.0  \n",
       "\n",
       "[4048 rows x 50 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Last step of Pipeline should implement fit or be the string 'passthrough'. '<__main__.KMeans object at 0x1289545b0>' (type <class '__main__.KMeans'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     24\u001b[0m [\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor),\n\u001b[1;32m     26\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m, clusterer)\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m initial_df\n\u001b[0;32m---> 30\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m sse\u001b[38;5;241m.\u001b[39mappend(pipe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[1;32m     32\u001b[0m score \u001b[38;5;241m=\u001b[39m silhouette_score(data,pipe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlabels_)\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    655\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    656\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    657\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    658\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    659\u001b[0m         )\n\u001b[0;32m--> 660\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:652\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m     )\n\u001b[1;32m    651\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 652\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:560\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[0;32m--> 560\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[1;32m    562\u001b[0m memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:350\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    349\u001b[0m ):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast step of Pipeline should implement fit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator, \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m    354\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Last step of Pipeline should implement fit or be the string 'passthrough'. '<__main__.KMeans object at 0x1289545b0>' (type <class '__main__.KMeans'>) doesn't"
     ]
    }
   ],
   "source": [
    "sse=[]\n",
    "silhouette_coefficients = []\n",
    "for k in range(2,11):\n",
    "    n_clusters = k\n",
    "    preprocessor = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            (\"pca\", PCA(n_components=4, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "    clusterer = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"kmeans\",\n",
    "            KMeans(\n",
    "                K=n_clusters,\n",
    "                max_iters=500,\n",
    "                plot_steps=True\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clusterer)\n",
    "    ]\n",
    "    )\n",
    "    data = initial_df\n",
    "    pipe.fit(data)\n",
    "    sse.append(pipe[\"clusterer\"][\"kmeans\"].inertia_)\n",
    "    score = silhouette_score(data,pipe[\"clusterer\"][\"kmeans\"].labels_)\n",
    "    silhouette_coefficients.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 11), sse)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df['power-usage-class']= pipe[\"clusterer\"][\"kmeans\"].labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 9, 1, 5, 7, 4, 8, 6], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df['power-usage-class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = initial_df.drop(columns=[label])\n",
    "y = initial_df[label]\n",
    "\n",
    "# X_test = test_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 4048\n",
      "Jumlah data train: 3238\n",
      "Jumlah data validasi: 810\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Jumlah data:\", len(initial_df))\n",
    "print(\"Jumlah data train:\", len(X_train))\n",
    "print(\"Jumlah data validasi:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and X_val have the same columns: True\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train and X_val have the same columns:\", is_same_cols(X_train, X_val, label))\n",
    "# print(\"X_test has the same columns as X_train:\", is_same_cols(X_train, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Outliers Value to NaN [TENTATIVE: Based on EDA Boxplot]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_handler_iforest = FeatureOutliersHandling(\n",
    "    numerical_features=numerical_features,\n",
    "    contamination=0.05, \n",
    "    outlier_method='iforest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iforest.fit_transform(X_train)\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IQR-ZScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_handler_iqr_zscore = FeatureOutliersHandling(\n",
    "#     numerical_features=numerical_features, \n",
    "#     contamination=0.05, \n",
    "#     outlier_method='iqr-zscore'\n",
    "# )\n",
    "\n",
    "# outlier_handler_iqr_zscore.plot_boxplots_for_numerical_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iqr_zscore.fit_transform(X_train, numerical_features_to_handle=numerical_features)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Impute Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = FeatureImputer(\n",
    "    numerical_features=numerical_features,\n",
    "    categorical_features=categorical_features,\n",
    "    int_num_features=numerical_features, # depends on the dataset\n",
    "    imputer_type='iterative',\n",
    "    num_strategy='mean',\n",
    "    cat_strategy='most_frequent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_date      0\n",
       "interval_1     0\n",
       "interval_2     0\n",
       "interval_3     0\n",
       "interval_4     0\n",
       "interval_5     0\n",
       "interval_6     0\n",
       "interval_7     0\n",
       "interval_8     0\n",
       "interval_9     0\n",
       "interval_10    0\n",
       "interval_11    0\n",
       "interval_12    0\n",
       "interval_13    0\n",
       "interval_14    0\n",
       "interval_15    0\n",
       "interval_16    0\n",
       "interval_17    0\n",
       "interval_18    0\n",
       "interval_19    0\n",
       "interval_20    0\n",
       "interval_21    0\n",
       "interval_22    0\n",
       "interval_23    0\n",
       "interval_24    0\n",
       "interval_25    0\n",
       "interval_26    0\n",
       "interval_27    0\n",
       "interval_28    0\n",
       "interval_29    0\n",
       "interval_30    0\n",
       "interval_31    0\n",
       "interval_32    0\n",
       "interval_33    0\n",
       "interval_34    0\n",
       "interval_35    0\n",
       "interval_36    0\n",
       "interval_37    0\n",
       "interval_38    0\n",
       "interval_39    0\n",
       "interval_40    0\n",
       "interval_41    0\n",
       "interval_42    0\n",
       "interval_43    0\n",
       "interval_44    0\n",
       "interval_45    0\n",
       "interval_46    0\n",
       "interval_47    0\n",
       "interval_48    0\n",
       "id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = imputer.fit_transform(X_train)\n",
    "# X_val = imputer.transform(X_val)\n",
    "# # X_test = imputer.transform(X_test)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resampling [TENTATIVE: Based on Label Distribution]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = {1: 786, 2: 786}\n",
    "\n",
    "# resampler = FeatureResampling(\n",
    "#     resampling_method='oversampling',\n",
    "#     categorical_features=categorical_features,\n",
    "#     sampling_strategy=sampling_strategy,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Sebelum Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = resampler.fit_transform(X_train, y_train)\n",
    "\n",
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Setelah Oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Label [TENTATIVE: If Label is Categorical Object]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = FeatureLabelEncoder()\n",
    "\n",
    "# y_train = label_encoder.fit_transform(y_train)\n",
    "# y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# label_encoder.get_encoding_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Binning [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = FeatureDiscretizer(\n",
    "    n_bins=5,\n",
    "    encode='ordinal',\n",
    "    strategy='uniform',\n",
    "    numerical_features_to_discretize=['tahun_kelahiran']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = discretizer.fit_transform(X_train)\n",
    "# X_val = discretizer.transform(X_val)\n",
    "# X_test = discretizer.transform(X_test)\n",
    "# discretizer.get_bin_edges()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical Features : Rare Categories Grouping [OPTIONAL: If Column has Rare Categories]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features_to_group = ['status_pernikahan', 'pendidikan']\n",
    "\n",
    "# rare_grouping = FeatureRareCategoriesGrouping(\n",
    "#     categorical_features=categorical_features_to_group,\n",
    "#     threshold=0.1,\n",
    "#     rare_label='Rare'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} before rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = rare_grouping.fit_transform(X_train)\n",
    "# X_val = rare_grouping.transform(X_val)\n",
    "# X_test = rare_grouping.transform(X_test)\n",
    "\n",
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} after rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Polynomial Features [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_poly = [\n",
    "#     'pembelian_diskon',\n",
    "#     'pembelian_toko',\n",
    "#     'pembelian_web'\n",
    "# ]\n",
    "\n",
    "# poly_features_adder = FeaturePolynomialAdder(\n",
    "#     degree=2,\n",
    "#     interaction_only=False,\n",
    "#     include_bias=False,\n",
    "#     columns=columns_to_poly\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = poly_features_adder.fit_transform(X_train)\n",
    "# X_val = poly_features_adder.transform(X_val)\n",
    "# X_test = poly_features_adder.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Power Transform [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_transform = [\n",
    "#     'belanja_buah',\n",
    "#     'belanja_daging',\n",
    "#     'belanja_ikan',\n",
    "#     'belanja_kue',\n",
    "# ]\n",
    "\n",
    "# # Inisialisasi transformer\n",
    "# power_transformer = FeaturePowerTransformer(\n",
    "#     method='yeo-johnson',\n",
    "#     standardize=True,\n",
    "#     columns=numerical_features_to_transform\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data sebelum transformasi\n",
    "# X_train_before = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Fit dan transform data\n",
    "# X_train = power_transformer.fit_transform(X_train)\n",
    "# X_val = power_transformer.transform(X_val)\n",
    "# X_test = power_transformer.transform(X_test)\n",
    "\n",
    "# # Data setelah transformasi\n",
    "# X_train_after = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Plot distribusi sebelum dan sesudah transformasi\n",
    "# power_transformer.plot_kde_hist_before_after(X_train_before, X_train_after)\n",
    "\n",
    "# # Dapatkan nilai lambda untuk setiap fitur\n",
    "# print(\"Lambda values for power transformation:\")\n",
    "# print(power_transformer.get_lambdas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Grouping (min,max,mean,median,std) [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_grouping = [\n",
    "#     'belanja_buah', \n",
    "#     'belanja_daging', \n",
    "#     'belanja_ikan', \n",
    "#     'belanja_kue'\n",
    "# ]\n",
    "\n",
    "# grouping_transformer = FeatureGroupingNumeric(\n",
    "#     numerical_features_to_grouping=numerical_features_to_grouping,\n",
    "#     aggregations=['min', 'max', 'mean', 'median', 'std'],\n",
    "#     columns_name='belanja'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = grouping_transformer.fit_transform(X_train)\n",
    "# X_val = grouping_transformer.transform(X_val)\n",
    "# X_test = grouping_transformer.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Dimensionality Reduction [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_pca = ['belanja_buah','belanja_daging','belanja_ikan','belanja_kue']\n",
    "n_components = 4\n",
    "\n",
    "reducer = FeatureDimensionReducer(\n",
    "    method='pca',\n",
    "    n_components=n_components,\n",
    "    numeric_features_to_reduce=numeric_features_pca,\n",
    "    column_names='belanja_pca'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reducer.fit_transform(X_train) \n",
    "\n",
    "print(f\"Explained variance ratio for {n_components} components:\\n\", reducer.get_variance_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_pca = reducer.transform(X_val)\n",
    "# X_test_pca = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_lda = ['pembelian_diskon','pembelian_toko','pembelian_web']\n",
    "n_components = 2\n",
    "\n",
    "reducer = FeatureDimensionReducer(\n",
    "    method='lda',\n",
    "    n_components=n_components,\n",
    "    numeric_features_to_reduce=numeric_features_lda,\n",
    "    column_names='pembelian_lda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = reducer.fit_transform(X_train, y_train)\n",
    "# X_val_lda = reducer.transform(X_val)\n",
    "# X_test_lda = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the ordinal features from the categorical features\n",
    "ordinal_features_dict = {\n",
    "    # 'pendidikan': ['SMP', 'SMA', 'Sarjana', 'Magister', 'Doktor'],\n",
    "    'status_pernikahan': ['Rencana Menikah', 'Menikah', 'Sendiri', 'Cerai', 'Cerai Mati']\n",
    "}\n",
    "# -----------------------------------\n",
    "\n",
    "# Define the nominal categorical features for one-hot encoding\n",
    "one_hot_features = ['pendidikan']\n",
    "\n",
    "encoder = FeatureEncoder(\n",
    "    ordinal_features_dict=ordinal_features_dict,\n",
    "    one_hot_features=one_hot_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.fit_transform(X_train)\n",
    "X_val = encoder.transform(X_val)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler if the data is normally distributed, otherwise use MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = FeatureScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# # X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_features, non_normal_features = scaler.get_scaler_columns()\n",
    "\n",
    "# print(\"Normal Features:\", normal_features)\n",
    "# print(\"Non-Normal Features:\", non_normal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Preprocessing to Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Simpan X_train, y_train, X_val, y_val, X_test ke dalam file pickle\n",
    "with open('processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val,\n",
    "        'X_test': X_test    \n",
    "    }, f)\n",
    "\n",
    "print(\"Data has been saved to 'processed_data.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Memisahkan data yang telah dimuat kembali ke variabel masing-masing\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "\n",
    "# Verifikasi bahwa data telah berhasil dimuat\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from cuml.linear_model import LogisticRegression as cuLogisticRegression\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNeighborsClassifier\n",
    "from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\n",
    "from cuml.svm import SVC as cuSVC  # cuML GPU-based SVC\n",
    "import cudf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC  # sklearn SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class Modelling:\n",
    "    def __init__(self, config, random_state=42, use_gpu=False):\n",
    "        self.config = config\n",
    "        self.random_state = random_state\n",
    "        self.use_gpu = use_gpu\n",
    "        self.models = self._initialize_models()\n",
    "        self.trained_models = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.final_trained_model = None\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        models = {}\n",
    "        if self.config.get(\"logreg\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based Logistic Regression\n",
    "                models[\"logreg\"] = cuLogisticRegression()\n",
    "            else:\n",
    "                models[\"logreg\"] = LogisticRegression(\n",
    "                    random_state=self.random_state)\n",
    "\n",
    "        if self.config.get(\"knn\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = cuKNeighborsClassifier()\n",
    "            else:\n",
    "                # CPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = KNeighborsClassifier()\n",
    "\n",
    "        if self.config.get(\"dt\"):\n",
    "            models[\"dt\"] = DecisionTreeClassifier(\n",
    "                random_state=self.random_state)  # Always use sklearn DecisionTree\n",
    "\n",
    "        if self.config.get(\"rf\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"rf\"] = cuRandomForestClassifier(\n",
    "                    random_state=self.random_state)  # GPU-based RandomForest\n",
    "            else:\n",
    "                models[\"rf\"] = RandomForestClassifier(\n",
    "                    random_state=self.random_state)  # CPU-based RandomForest\n",
    "\n",
    "        if self.config.get(\"xgb\"):\n",
    "            models[\"xgb\"] = XGBClassifier(\n",
    "                use_label_encoder=False,\n",
    "                random_state=self.random_state,\n",
    "                tree_method='gpu_hist' if self.use_gpu else 'hist',  # GPU usage for XGBoost\n",
    "                predictor='gpu_predictor' if self.use_gpu else 'cpu_predictor'\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"lgbm\"):\n",
    "            models[\"lgbm\"] = LGBMClassifier(\n",
    "                random_state=self.random_state,\n",
    "                device='cpu'  # Force CPU usage for LightGBM due to OpenCL issues\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"catboost\"):\n",
    "            models[\"catboost\"] = CatBoostClassifier(\n",
    "                silent=True,\n",
    "                random_state=self.random_state,\n",
    "                task_type='GPU' if self.use_gpu else 'CPU'  # GPU usage for CatBoost\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"support_vector\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"support_vector\"] = cuSVC()  # GPU-based SVC from cuML\n",
    "            else:\n",
    "                models[\"support_vector\"] = SVC(\n",
    "                    probability=True, random_state=self.random_state)  # CPU-based SVC\n",
    "\n",
    "        return models\n",
    "\n",
    "    def _evaluate_model(self, name, model, X_val, y_val):\n",
    "        try:\n",
    "            if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                # Convert input to cuDF for cuML models\n",
    "                X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "                y_val_cudf = cudf.Series(y_val)\n",
    "\n",
    "                print(f\"X_val_cudf dtypes: {X_val_cudf.dtypes}\")\n",
    "                print(f\"y_val_cudf dtype: {y_val_cudf.dtype}\")\n",
    "\n",
    "                y_pred = model.predict(X_val_cudf)\n",
    "                print(f\"y_pred type: {type(y_pred)}, dtype: {y_pred.dtype}\")\n",
    "\n",
    "                # Convert to NumPy arrays for compatibility with scikit-learn metrics\n",
    "                y_pred = y_pred.to_numpy()\n",
    "                y_val_array = y_val_cudf.to_numpy()\n",
    "            else:\n",
    "                # For sklearn models\n",
    "                y_pred = model.predict(X_val)\n",
    "                y_val_array = y_val\n",
    "\n",
    "            metrics = {\n",
    "                'model': name,\n",
    "                'accuracy': accuracy_score(y_val_array, y_pred),\n",
    "                'precision': precision_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'recall': recall_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'f1_score': f1_score(y_val_array, y_pred, average='weighted', zero_division=0)\n",
    "            }\n",
    "            return pd.DataFrame([metrics])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in _evaluate_model for {name}: {str(e)}\")\n",
    "            return pd.DataFrame([{'model': name, 'error': str(e)}])\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, metric='f1_score', n_select=None):\n",
    "        evaluation_results = pd.DataFrame()\n",
    "\n",
    "        if self.use_gpu:\n",
    "            X_train_cudf = cudf.DataFrame.from_pandas(X_train)\n",
    "            y_train_cudf = cudf.Series(y_train)\n",
    "        else:\n",
    "            X_train_cudf = X_train\n",
    "            y_train_cudf = y_train\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training model: {name}\")\n",
    "            try:\n",
    "                if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                    model.fit(X_train_cudf, y_train_cudf)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                self.trained_models[name] = model\n",
    "\n",
    "                # Evaluate model\n",
    "                metrics_df = self._evaluate_model(name, model, X_val, y_val)\n",
    "                evaluation_results = pd.concat(\n",
    "                    [evaluation_results, metrics_df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        evaluation_results = evaluation_results.sort_values(\n",
    "            by=metric, ascending=False)\n",
    "        # Displaying results as HTML table\n",
    "        html_table = evaluation_results.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        # Select best models\n",
    "        if n_select:\n",
    "            top_models = evaluation_results.head(n_select)['model'].tolist()\n",
    "            self.best_model = [self.trained_models[name]\n",
    "                               for name in top_models]\n",
    "            self.best_model_name = top_models\n",
    "        else:\n",
    "            self.best_model_name = evaluation_results.iloc[0]['model']\n",
    "            self.best_model = self.trained_models[self.best_model_name]\n",
    "\n",
    "    def train_final(self, X_train, X_val, y_train, y_val, model=None):\n",
    "        \"\"\"\n",
    "        Train a model on the combined train and validation dataset.\n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - X_val: Validation features\n",
    "        - y_train: Training labels\n",
    "        - y_val: Validation labels\n",
    "        - model: (Optional) Specific model to train on combined data. If None, the first model from best_model will be used.\n",
    "        \"\"\"\n",
    "        # Combine train and validation datasets\n",
    "        X_combined = pd.concat([X_train, X_val], axis=0)\n",
    "        y_combined = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "        # If no model is provided, check best_model\n",
    "        if model is None:\n",
    "            if not self.best_model:\n",
    "                raise ValueError(\n",
    "                    \"Please train the models first using `train()` before calling `train_final()`.\")\n",
    "\n",
    "            # If best_model is a list of models, pick the first one\n",
    "            if isinstance(self.best_model, list):\n",
    "                # Take the first model if it's an array\n",
    "                model = self.best_model[0]\n",
    "                model_name = self.best_model_name[0]\n",
    "            else:\n",
    "                model = self.best_model\n",
    "                model_name = self.best_model_name\n",
    "\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "\n",
    "        print(f\"Training final model: {model_name}\")\n",
    "        model.fit(X_combined, y_combined)\n",
    "\n",
    "        # Store the trained final model\n",
    "        self.final_trained_model = model\n",
    "\n",
    "        return self.final_trained_model\n",
    "\n",
    "    def voting_ensemble(self, X_train, y_train, X_val, y_val, n_select=3, voting='soft'):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using voting ensemble.\")\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=selected_models, voting=voting)\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"VotingClassifier\", voting_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return voting_clf\n",
    "\n",
    "    def stacking_ensemble(self, X_train, y_train, X_val, y_val, meta_model=None, n_select=3):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using stacking ensemble.\")\n",
    "\n",
    "        if meta_model is None:\n",
    "            meta_model = LogisticRegression(random_state=self.random_state)\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=selected_models, final_estimator=meta_model)\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"StackingClassifier\", stacking_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return stacking_clf\n",
    "\n",
    "    def plot(self, model, X_val, y_val):\n",
    "        \"\"\"Plot confusion matrix, classification report, and ROC-AUC curve.\"\"\"\n",
    "\n",
    "        # Check if the model supports predict_proba (required for ROC-AUC)\n",
    "        supports_proba = hasattr(model, \"predict_proba\")\n",
    "\n",
    "        if self.use_gpu and isinstance(model, (cuLogisticRegression, cuKNeighborsClassifier, cuRandomForestClassifier, cuSVC)):\n",
    "            X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "            y_val_cudf = cudf.Series(y_val)\n",
    "            y_pred = model.predict(X_val_cudf).to_numpy()\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val_cudf).to_numpy()\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix for {model.__class__.__name__}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        # Classification Report\n",
    "        print(f'Classification Report for {model.__class__.__name__}:\\n')\n",
    "        print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "        # ROC-AUC Plot\n",
    "        if supports_proba:\n",
    "            # Check if it is a binary classification problem\n",
    "            if len(np.unique(y_val)) == 2:\n",
    "                fpr, tpr, _ = roc_curve(y_val, y_proba[:, 1])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                         label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'ROC Curve for {model.__class__.__name__}')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                # For multi-class classification, binarize the labels\n",
    "                y_val_bin = label_binarize(y_val, classes=np.unique(y_val))\n",
    "                n_classes = y_val_bin.shape[1]\n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "\n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(\n",
    "                        y_val_bin[:, i], y_proba[:, i])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "                # Plot ROC curve for each class\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                             label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(\n",
    "                    f'ROC Curve for {model.__class__.__name__} (multi-class)')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\n",
    "                f'ROC-AUC cannot be plotted for {model.__class__.__name__} as it does not support probability estimates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logreg\": True,\n",
    "    \"knn\": True,\n",
    "    \"dt\": True,\n",
    "    \"rf\": True,\n",
    "    \"xgb\": True,\n",
    "    \"lgbm\": True,\n",
    "    \"catboost\": True,\n",
    "    \"support_vector\": True,\n",
    "}\n",
    "# Initialize modelling with GPU enabled\n",
    "modelling = Modelling(config=config, random_state=42, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model dan memilih 3 model terbaik\n",
    "modelling.train(X_train, y_train, X_val, y_val, metric='f1_score', n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Voting ensemble dengan n_select=5 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "voting_model = modelling.voting_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Stacking ensemble dengan n_select=4 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "stacking_model = modelling.stacking_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation confussion matrix and classification report\n",
    "modelling.plot(modelling.best_model[0], X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = modelling.train_final(X_train, X_val, y_train, y_val)\n",
    "\n",
    "# prediction\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubes2-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
