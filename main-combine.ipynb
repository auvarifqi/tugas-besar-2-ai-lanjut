{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 style=\"font-weight: bold;\">\n",
    "    Binary Classification from Tabular Data</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deskripsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan clustering sebagai salah satu metode feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from class_reg_preprocessing import (\n",
    "    FeatureOutliersHandling,\n",
    "    FeatureImputer,\n",
    "    FeatureResampling,\n",
    "    FeatureLabelEncoder,\n",
    "    FeatureDiscretizer,\n",
    "    FeatureRareCategoriesGrouping,\n",
    "    FeaturePolynomialAdder,\n",
    "    FeaturePowerTransformer,\n",
    "    FeatureGroupingNumeric,\n",
    "    FeatureDimensionReducer,\n",
    "    FeatureEncoder,\n",
    "    FeatureScaler,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_date</th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/1/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/2/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/3/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/4/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/5/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>3/31/2021 0:00</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4/1/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>4/2/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>4/3/2021 0:00</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>4/4/2021 0:00</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4048 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           read_date  interval_1  interval_2  interval_3  interval_4  \\\n",
       "0           3/1/2021      0.0625      0.0500      0.0687      0.0750   \n",
       "1           3/2/2021      0.0625      0.0500      0.0687      0.0625   \n",
       "2           3/3/2021      0.0625      0.0687      0.0500      0.0562   \n",
       "3           3/4/2021      0.0625      0.0625      0.0687      0.0500   \n",
       "4           3/5/2021      0.0625      0.0625      0.0500      0.0625   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "4043  3/31/2021 0:00      0.2125      0.2000      0.1625      0.1750   \n",
       "4044   4/1/2021 0:00      0.1625      0.1625      0.1500      0.1500   \n",
       "4045   4/2/2021 0:00      0.1625      0.2000      0.2125      0.1625   \n",
       "4046   4/3/2021 0:00      0.2250      0.2250      0.1625      0.1750   \n",
       "4047   4/4/2021 0:00      0.2000      0.1625      0.1625      0.2000   \n",
       "\n",
       "      interval_5  interval_6  interval_7  interval_8  interval_9  ...  \\\n",
       "0         0.0687      0.0500      0.0625      0.0687      0.0687  ...   \n",
       "1         0.0625      0.0562      0.0562      0.0625      0.0687  ...   \n",
       "2         0.0687      0.0625      0.0625      0.0625      0.0500  ...   \n",
       "3         0.0562      0.0625      0.0625      0.0625      0.0562  ...   \n",
       "4         0.0687      0.0625      0.0687      0.0562      0.0500  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "4043      0.2375      0.2125      0.1875      0.1750      0.2000  ...   \n",
       "4044      0.2000      0.1750      0.1625      0.1625      0.1500  ...   \n",
       "4045      0.1625      0.1375      0.1500      0.1250      0.1875  ...   \n",
       "4046      0.1750      0.1500      0.1500      0.2125      0.1625  ...   \n",
       "4047      0.1500      0.1500      0.1750      0.1750      0.1375  ...   \n",
       "\n",
       "      interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "0          0.0812       0.0687       0.0687       0.0562       0.0562   \n",
       "1          0.1375       0.0750       0.0687       0.0625       0.0625   \n",
       "2          0.1875       0.1062       0.0750       0.0687       0.0687   \n",
       "3          0.1125       0.0875       0.0687       0.0625       0.0562   \n",
       "4          0.0812       0.0562       0.0687       0.0625       0.0625   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4043       0.3375       0.3875       0.3375       0.3875       0.2500   \n",
       "4044       0.2375       0.2000       0.2125       0.2000       0.2000   \n",
       "4045       0.2500       0.2750       0.3750       0.3375       0.3250   \n",
       "4046       0.3375       0.4000       0.3500       0.2625       0.4000   \n",
       "4047       0.5250       0.4125       0.4000       0.4500       0.3625   \n",
       "\n",
       "      interval_46  interval_47  interval_48  id  label  \n",
       "0          0.0687       0.0687       0.0625   1      1  \n",
       "1          0.0562       0.0625       0.0625   1      1  \n",
       "2          0.0625       0.0562       0.0562   1      1  \n",
       "3          0.0625       0.0625       0.0687   1      1  \n",
       "4          0.0625       0.0562       0.0500   1      1  \n",
       "...           ...          ...          ...  ..    ...  \n",
       "4043       0.5125       0.4750       0.2000  57      0  \n",
       "4044       0.2875       0.1875       0.2250  57      0  \n",
       "4045       0.2625       0.3000       0.3500  57      0  \n",
       "4046       0.3375       0.8375       0.6625  57      0  \n",
       "4047       0.6500       1.3500       0.7875  57      0  \n",
       "\n",
       "[4048 rows x 51 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: define initial dataframes\n",
    "initial_df = pd.read_csv(f'{data_path}/EV_data.csv')\n",
    "# -----------------------------------\n",
    "\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: define test dataframe\n",
    "# test_features_df = pd.read_csv(f'{data_path}/test_features.csv')\n",
    "\n",
    "# submisssion_ids = test_features_df['ID']\n",
    "\n",
    "# test_features_df = test_features_df.drop(columns=['ID'])\n",
    "# # -------------------------------------\n",
    "\n",
    "# test_features_df = test_features_df.reindex(sorted(test_features_df.columns), axis=1)\n",
    "\n",
    "# test_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Target and Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define which columns are target labels\n",
    "label = 'label'\n",
    "# -----------------------------------\n",
    "# TODO: define which columns are categorical and which are numerical features\n",
    "categorical_features = ['id']\n",
    "\n",
    "# get all columns with float64 and int64 data types\n",
    "numerical_features = initial_df.select_dtypes(include=['float64']).columns\n",
    "# -----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Unnecessary Columns [TENTATIVE]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define columns to drop\n",
    "columns_to_drop = ['label', 'read_date']\n",
    "# -----------------------------------\n",
    "\n",
    "categorical_features = [col for col in categorical_features if col not in columns_to_drop]\n",
    "numerical_features = [col for col in numerical_features if col not in columns_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for initial data before removing duplicates: 4048\n",
      "Row count for initial data after removing duplicates: 4048\n"
     ]
    }
   ],
   "source": [
    "print('Row count for initial data before removing duplicates:', len(initial_df))\n",
    "initial_df.drop_duplicates(inplace=True)\n",
    "print('Row count for initial data after removing duplicates:', len(initial_df))\n",
    "initial_df.reset_index(drop=True, inplace=True) # Reset the index after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df.drop(columns=columns_to_drop)\n",
    "# test_features_df = test_features_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Wrong Value to NaN [Tentative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_values = '5'\n",
    "\n",
    "# initial_df['pendidikan'] = initial_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# initial_df['status_pernikahan'] = initial_df['status_pernikahan'].replace(wrong_values, np.nan)\n",
    "\n",
    "# test_features_df['pendidikan'] = test_features_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# test_features_df['status_pernikahan'] = test_features_df['status_pernikahan'].replace(wrong_values, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check Similarity Columns between Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_cols(df1: pd.DataFrame, df2: pd.DataFrame, label: str):\n",
    "    \"\"\"\n",
    "    Function to check if two DataFrames have the same columns, excluding the label column if it exists.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1: First DataFrame\n",
    "    - df2: Second DataFrame\n",
    "    - label: The name of the label column to exclude from the comparison (default is 'label').\n",
    "    \n",
    "    Returns:\n",
    "    - Boolean value indicating whether the columns are the same, excluding the label column\n",
    "    \"\"\"\n",
    "    # Exclude the label column if it exists in either DataFrame\n",
    "    df1_cols = df1.columns.drop(label) if label in df1.columns else df1.columns\n",
    "    df2_cols = df2.columns.drop(label) if label in df2.columns else df2.columns\n",
    "\n",
    "    # Compare the remaining columns\n",
    "    return df1_cols.equals(df2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Initial and test features have the same columns:', is_same_cols(initial_df, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grouping by ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df.groupby(['id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88 entries, 1 to 88\n",
      "Data columns (total 48 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   interval_1   88 non-null     float64\n",
      " 1   interval_2   88 non-null     float64\n",
      " 2   interval_3   88 non-null     float64\n",
      " 3   interval_4   88 non-null     float64\n",
      " 4   interval_5   88 non-null     float64\n",
      " 5   interval_6   88 non-null     float64\n",
      " 6   interval_7   88 non-null     float64\n",
      " 7   interval_8   88 non-null     float64\n",
      " 8   interval_9   88 non-null     float64\n",
      " 9   interval_10  88 non-null     float64\n",
      " 10  interval_11  88 non-null     float64\n",
      " 11  interval_12  88 non-null     float64\n",
      " 12  interval_13  88 non-null     float64\n",
      " 13  interval_14  88 non-null     float64\n",
      " 14  interval_15  88 non-null     float64\n",
      " 15  interval_16  88 non-null     float64\n",
      " 16  interval_17  88 non-null     float64\n",
      " 17  interval_18  88 non-null     float64\n",
      " 18  interval_19  88 non-null     float64\n",
      " 19  interval_20  88 non-null     float64\n",
      " 20  interval_21  88 non-null     float64\n",
      " 21  interval_22  88 non-null     float64\n",
      " 22  interval_23  88 non-null     float64\n",
      " 23  interval_24  88 non-null     float64\n",
      " 24  interval_25  88 non-null     float64\n",
      " 25  interval_26  88 non-null     float64\n",
      " 26  interval_27  88 non-null     float64\n",
      " 27  interval_28  88 non-null     float64\n",
      " 28  interval_29  88 non-null     float64\n",
      " 29  interval_30  88 non-null     float64\n",
      " 30  interval_31  88 non-null     float64\n",
      " 31  interval_32  88 non-null     float64\n",
      " 32  interval_33  88 non-null     float64\n",
      " 33  interval_34  88 non-null     float64\n",
      " 34  interval_35  88 non-null     float64\n",
      " 35  interval_36  88 non-null     float64\n",
      " 36  interval_37  88 non-null     float64\n",
      " 37  interval_38  88 non-null     float64\n",
      " 38  interval_39  88 non-null     float64\n",
      " 39  interval_40  88 non-null     float64\n",
      " 40  interval_41  88 non-null     float64\n",
      " 41  interval_42  88 non-null     float64\n",
      " 42  interval_43  88 non-null     float64\n",
      " 43  interval_44  88 non-null     float64\n",
      " 44  interval_45  88 non-null     float64\n",
      " 45  interval_46  88 non-null     float64\n",
      " 46  interval_47  88 non-null     float64\n",
      " 47  interval_48  88 non-null     float64\n",
      "dtypes: float64(48)\n",
      "memory usage: 33.7 KB\n"
     ]
    }
   ],
   "source": [
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        # list of sample indices for each cluster\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "\n",
    "        # the centers (mean vector) for each cluster\n",
    "        self.centroids = []\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # initialize\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        # optimize clusters\n",
    "        for _ in range(self.max_iters):\n",
    "            # assign samples to closest centroids (create clusters)\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            # calculate new centroids from the clusters\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "        # classify samples as the index of their clusters\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        # each sample will get the label of the cluster it was assigned to\n",
    "        labels = np.empty(self.n_samples)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_idx in cluster:\n",
    "                labels[sample_idx] = cluster_idx\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        # assign the samples to the closest centroids\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        # distance of the current sample to each centroid\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return closest_idx\n",
    "\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        # assign mean value of clusters to centroids\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "            centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids):\n",
    "        # distances between old and new centroids, for all centroids\n",
    "        distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)]\n",
    "        return sum(distances) == 0\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        for i, index in enumerate(self.clusters):\n",
    "            point = self.X[index].T\n",
    "            ax.scatter(*point)\n",
    "\n",
    "        for point in self.centroids:\n",
    "            ax.scatter(*point, marker=\"x\", color=\"black\", linewidth=2)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = Pipeline(\n",
    "   [\n",
    "       (\n",
    "           \"kmeans\",\n",
    "           KMeans(\n",
    "               K=n_clusters,\n",
    "               max_iters=500,\n",
    "               plot_steps=True\n",
    "           ),\n",
    "       ),\n",
    "   ]\n",
    ")\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clusterer)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Last step of Pipeline should implement fit or be the string 'passthrough'. '<__main__.KMeans object at 0x1289545b0>' (type <class '__main__.KMeans'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     24\u001b[0m [\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor),\n\u001b[1;32m     26\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m, clusterer)\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m initial_df\n\u001b[0;32m---> 30\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m sse\u001b[38;5;241m.\u001b[39mappend(pipe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[1;32m     32\u001b[0m score \u001b[38;5;241m=\u001b[39m silhouette_score(data,pipe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusterer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlabels_)\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    655\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    656\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    657\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    658\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    659\u001b[0m         )\n\u001b[0;32m--> 660\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:652\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m     )\n\u001b[1;32m    651\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 652\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:560\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[0;32m--> 560\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[1;32m    562\u001b[0m memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[0;32m~/anaconda3/envs/tubes2-ai/lib/python3.10/site-packages/sklearn/pipeline.py:350\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    349\u001b[0m ):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast step of Pipeline should implement fit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator, \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m    354\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Last step of Pipeline should implement fit or be the string 'passthrough'. '<__main__.KMeans object at 0x1289545b0>' (type <class '__main__.KMeans'>) doesn't"
     ]
    }
   ],
   "source": [
    "sse=[]\n",
    "silhouette_coefficients = []\n",
    "for k in range(2,11):\n",
    "    n_clusters = k\n",
    "    preprocessor = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", MinMaxScaler()),\n",
    "            (\"pca\", PCA(n_components=4, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "    clusterer = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"kmeans\",\n",
    "            KMeans(\n",
    "                K=n_clusters,\n",
    "                max_iters=500,\n",
    "                plot_steps=True\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clusterer)\n",
    "    ]\n",
    "    )\n",
    "    data = initial_df\n",
    "    pipe.fit(data)\n",
    "    sse.append(pipe[\"clusterer\"][\"kmeans\"].inertia_)\n",
    "    score = silhouette_score(data,pipe[\"clusterer\"][\"kmeans\"].labels_)\n",
    "    silhouette_coefficients.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 11), sse)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df['power-usage-class']= pipe[\"clusterer\"][\"kmeans\"].labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 9, 1, 5, 7, 4, 8, 6], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df['power-usage-class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = initial_df.drop(columns=[label])\n",
    "y = initial_df[label]\n",
    "\n",
    "# X_test = test_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 4048\n",
      "Jumlah data train: 3238\n",
      "Jumlah data validasi: 810\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Jumlah data:\", len(initial_df))\n",
    "print(\"Jumlah data train:\", len(X_train))\n",
    "print(\"Jumlah data validasi:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and X_val have the same columns: True\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train and X_val have the same columns:\", is_same_cols(X_train, X_val, label))\n",
    "# print(\"X_test has the same columns as X_train:\", is_same_cols(X_train, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Outliers Value to NaN [TENTATIVE: Based on EDA Boxplot]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_handler_iforest = FeatureOutliersHandling(\n",
    "    numerical_features=numerical_features,\n",
    "    contamination=0.05, \n",
    "    outlier_method='iforest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iforest.fit_transform(X_train)\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IQR-ZScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_handler_iqr_zscore = FeatureOutliersHandling(\n",
    "#     numerical_features=numerical_features, \n",
    "#     contamination=0.05, \n",
    "#     outlier_method='iqr-zscore'\n",
    "# )\n",
    "\n",
    "# outlier_handler_iqr_zscore.plot_boxplots_for_numerical_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iqr_zscore.fit_transform(X_train, numerical_features_to_handle=numerical_features)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Impute Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = FeatureImputer(\n",
    "    numerical_features=numerical_features,\n",
    "    categorical_features=categorical_features,\n",
    "    int_num_features=numerical_features, # depends on the dataset\n",
    "    imputer_type='iterative',\n",
    "    num_strategy='mean',\n",
    "    cat_strategy='most_frequent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_date      0\n",
       "interval_1     0\n",
       "interval_2     0\n",
       "interval_3     0\n",
       "interval_4     0\n",
       "interval_5     0\n",
       "interval_6     0\n",
       "interval_7     0\n",
       "interval_8     0\n",
       "interval_9     0\n",
       "interval_10    0\n",
       "interval_11    0\n",
       "interval_12    0\n",
       "interval_13    0\n",
       "interval_14    0\n",
       "interval_15    0\n",
       "interval_16    0\n",
       "interval_17    0\n",
       "interval_18    0\n",
       "interval_19    0\n",
       "interval_20    0\n",
       "interval_21    0\n",
       "interval_22    0\n",
       "interval_23    0\n",
       "interval_24    0\n",
       "interval_25    0\n",
       "interval_26    0\n",
       "interval_27    0\n",
       "interval_28    0\n",
       "interval_29    0\n",
       "interval_30    0\n",
       "interval_31    0\n",
       "interval_32    0\n",
       "interval_33    0\n",
       "interval_34    0\n",
       "interval_35    0\n",
       "interval_36    0\n",
       "interval_37    0\n",
       "interval_38    0\n",
       "interval_39    0\n",
       "interval_40    0\n",
       "interval_41    0\n",
       "interval_42    0\n",
       "interval_43    0\n",
       "interval_44    0\n",
       "interval_45    0\n",
       "interval_46    0\n",
       "interval_47    0\n",
       "interval_48    0\n",
       "id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = imputer.fit_transform(X_train)\n",
    "# X_val = imputer.transform(X_val)\n",
    "# # X_test = imputer.transform(X_test)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resampling [TENTATIVE: Based on Label Distribution]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = {1: 786, 2: 786}\n",
    "\n",
    "# resampler = FeatureResampling(\n",
    "#     resampling_method='oversampling',\n",
    "#     categorical_features=categorical_features,\n",
    "#     sampling_strategy=sampling_strategy,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Sebelum Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = resampler.fit_transform(X_train, y_train)\n",
    "\n",
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Setelah Oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Label [TENTATIVE: If Label is Categorical Object]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = FeatureLabelEncoder()\n",
    "\n",
    "# y_train = label_encoder.fit_transform(y_train)\n",
    "# y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# label_encoder.get_encoding_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Binning [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = FeatureDiscretizer(\n",
    "    n_bins=5,\n",
    "    encode='ordinal',\n",
    "    strategy='uniform',\n",
    "    numerical_features_to_discretize=['tahun_kelahiran']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = discretizer.fit_transform(X_train)\n",
    "# X_val = discretizer.transform(X_val)\n",
    "# X_test = discretizer.transform(X_test)\n",
    "# discretizer.get_bin_edges()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical Features : Rare Categories Grouping [OPTIONAL: If Column has Rare Categories]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features_to_group = ['status_pernikahan', 'pendidikan']\n",
    "\n",
    "# rare_grouping = FeatureRareCategoriesGrouping(\n",
    "#     categorical_features=categorical_features_to_group,\n",
    "#     threshold=0.1,\n",
    "#     rare_label='Rare'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} before rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = rare_grouping.fit_transform(X_train)\n",
    "# X_val = rare_grouping.transform(X_val)\n",
    "# X_test = rare_grouping.transform(X_test)\n",
    "\n",
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} after rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Polynomial Features [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_poly = [\n",
    "#     'pembelian_diskon',\n",
    "#     'pembelian_toko',\n",
    "#     'pembelian_web'\n",
    "# ]\n",
    "\n",
    "# poly_features_adder = FeaturePolynomialAdder(\n",
    "#     degree=2,\n",
    "#     interaction_only=False,\n",
    "#     include_bias=False,\n",
    "#     columns=columns_to_poly\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = poly_features_adder.fit_transform(X_train)\n",
    "# X_val = poly_features_adder.transform(X_val)\n",
    "# X_test = poly_features_adder.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Power Transform [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_transform = [\n",
    "#     'belanja_buah',\n",
    "#     'belanja_daging',\n",
    "#     'belanja_ikan',\n",
    "#     'belanja_kue',\n",
    "# ]\n",
    "\n",
    "# # Inisialisasi transformer\n",
    "# power_transformer = FeaturePowerTransformer(\n",
    "#     method='yeo-johnson',\n",
    "#     standardize=True,\n",
    "#     columns=numerical_features_to_transform\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data sebelum transformasi\n",
    "# X_train_before = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Fit dan transform data\n",
    "# X_train = power_transformer.fit_transform(X_train)\n",
    "# X_val = power_transformer.transform(X_val)\n",
    "# X_test = power_transformer.transform(X_test)\n",
    "\n",
    "# # Data setelah transformasi\n",
    "# X_train_after = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Plot distribusi sebelum dan sesudah transformasi\n",
    "# power_transformer.plot_kde_hist_before_after(X_train_before, X_train_after)\n",
    "\n",
    "# # Dapatkan nilai lambda untuk setiap fitur\n",
    "# print(\"Lambda values for power transformation:\")\n",
    "# print(power_transformer.get_lambdas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Grouping (min,max,mean,median,std) [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_grouping = [\n",
    "#     'belanja_buah', \n",
    "#     'belanja_daging', \n",
    "#     'belanja_ikan', \n",
    "#     'belanja_kue'\n",
    "# ]\n",
    "\n",
    "# grouping_transformer = FeatureGroupingNumeric(\n",
    "#     numerical_features_to_grouping=numerical_features_to_grouping,\n",
    "#     aggregations=['min', 'max', 'mean', 'median', 'std'],\n",
    "#     columns_name='belanja'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = grouping_transformer.fit_transform(X_train)\n",
    "# X_val = grouping_transformer.transform(X_val)\n",
    "# X_test = grouping_transformer.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Dimensionality Reduction [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_pca = ['belanja_buah','belanja_daging','belanja_ikan','belanja_kue']\n",
    "n_components = 4\n",
    "\n",
    "reducer = FeatureDimensionReducer(\n",
    "    method='pca',\n",
    "    n_components=n_components,\n",
    "    numeric_features_to_reduce=numeric_features_pca,\n",
    "    column_names='belanja_pca'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reducer.fit_transform(X_train) \n",
    "\n",
    "print(f\"Explained variance ratio for {n_components} components:\\n\", reducer.get_variance_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_pca = reducer.transform(X_val)\n",
    "# X_test_pca = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_lda = ['pembelian_diskon','pembelian_toko','pembelian_web']\n",
    "n_components = 2\n",
    "\n",
    "reducer = FeatureDimensionReducer(\n",
    "    method='lda',\n",
    "    n_components=n_components,\n",
    "    numeric_features_to_reduce=numeric_features_lda,\n",
    "    column_names='pembelian_lda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = reducer.fit_transform(X_train, y_train)\n",
    "# X_val_lda = reducer.transform(X_val)\n",
    "# X_test_lda = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the ordinal features from the categorical features\n",
    "ordinal_features_dict = {\n",
    "    # 'pendidikan': ['SMP', 'SMA', 'Sarjana', 'Magister', 'Doktor'],\n",
    "    'status_pernikahan': ['Rencana Menikah', 'Menikah', 'Sendiri', 'Cerai', 'Cerai Mati']\n",
    "}\n",
    "# -----------------------------------\n",
    "\n",
    "# Define the nominal categorical features for one-hot encoding\n",
    "one_hot_features = ['pendidikan']\n",
    "\n",
    "encoder = FeatureEncoder(\n",
    "    ordinal_features_dict=ordinal_features_dict,\n",
    "    one_hot_features=one_hot_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.fit_transform(X_train)\n",
    "X_val = encoder.transform(X_val)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler if the data is normally distributed, otherwise use MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = FeatureScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# # X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_features, non_normal_features = scaler.get_scaler_columns()\n",
    "\n",
    "# print(\"Normal Features:\", normal_features)\n",
    "# print(\"Non-Normal Features:\", non_normal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Preprocessing to Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Simpan X_train, y_train, X_val, y_val, X_test ke dalam file pickle\n",
    "with open('processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val,\n",
    "        'X_test': X_test    \n",
    "    }, f)\n",
    "\n",
    "print(\"Data has been saved to 'processed_data.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Memisahkan data yang telah dimuat kembali ke variabel masing-masing\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "\n",
    "# Verifikasi bahwa data telah berhasil dimuat\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from cuml.linear_model import LogisticRegression as cuLogisticRegression\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNeighborsClassifier\n",
    "from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\n",
    "from cuml.svm import SVC as cuSVC  # cuML GPU-based SVC\n",
    "import cudf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC  # sklearn SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class Modelling:\n",
    "    def __init__(self, config, random_state=42, use_gpu=False):\n",
    "        self.config = config\n",
    "        self.random_state = random_state\n",
    "        self.use_gpu = use_gpu\n",
    "        self.models = self._initialize_models()\n",
    "        self.trained_models = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.final_trained_model = None\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        models = {}\n",
    "        if self.config.get(\"logreg\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based Logistic Regression\n",
    "                models[\"logreg\"] = cuLogisticRegression()\n",
    "            else:\n",
    "                models[\"logreg\"] = LogisticRegression(\n",
    "                    random_state=self.random_state)\n",
    "\n",
    "        if self.config.get(\"knn\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = cuKNeighborsClassifier()\n",
    "            else:\n",
    "                # CPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = KNeighborsClassifier()\n",
    "\n",
    "        if self.config.get(\"dt\"):\n",
    "            models[\"dt\"] = DecisionTreeClassifier(\n",
    "                random_state=self.random_state)  # Always use sklearn DecisionTree\n",
    "\n",
    "        if self.config.get(\"rf\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"rf\"] = cuRandomForestClassifier(\n",
    "                    random_state=self.random_state)  # GPU-based RandomForest\n",
    "            else:\n",
    "                models[\"rf\"] = RandomForestClassifier(\n",
    "                    random_state=self.random_state)  # CPU-based RandomForest\n",
    "\n",
    "        if self.config.get(\"xgb\"):\n",
    "            models[\"xgb\"] = XGBClassifier(\n",
    "                use_label_encoder=False,\n",
    "                random_state=self.random_state,\n",
    "                tree_method='gpu_hist' if self.use_gpu else 'hist',  # GPU usage for XGBoost\n",
    "                predictor='gpu_predictor' if self.use_gpu else 'cpu_predictor'\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"lgbm\"):\n",
    "            models[\"lgbm\"] = LGBMClassifier(\n",
    "                random_state=self.random_state,\n",
    "                device='cpu'  # Force CPU usage for LightGBM due to OpenCL issues\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"catboost\"):\n",
    "            models[\"catboost\"] = CatBoostClassifier(\n",
    "                silent=True,\n",
    "                random_state=self.random_state,\n",
    "                task_type='GPU' if self.use_gpu else 'CPU'  # GPU usage for CatBoost\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"support_vector\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"support_vector\"] = cuSVC()  # GPU-based SVC from cuML\n",
    "            else:\n",
    "                models[\"support_vector\"] = SVC(\n",
    "                    probability=True, random_state=self.random_state)  # CPU-based SVC\n",
    "\n",
    "        return models\n",
    "\n",
    "    def _evaluate_model(self, name, model, X_val, y_val):\n",
    "        try:\n",
    "            if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                # Convert input to cuDF for cuML models\n",
    "                X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "                y_val_cudf = cudf.Series(y_val)\n",
    "\n",
    "                print(f\"X_val_cudf dtypes: {X_val_cudf.dtypes}\")\n",
    "                print(f\"y_val_cudf dtype: {y_val_cudf.dtype}\")\n",
    "\n",
    "                y_pred = model.predict(X_val_cudf)\n",
    "                print(f\"y_pred type: {type(y_pred)}, dtype: {y_pred.dtype}\")\n",
    "\n",
    "                # Convert to NumPy arrays for compatibility with scikit-learn metrics\n",
    "                y_pred = y_pred.to_numpy()\n",
    "                y_val_array = y_val_cudf.to_numpy()\n",
    "            else:\n",
    "                # For sklearn models\n",
    "                y_pred = model.predict(X_val)\n",
    "                y_val_array = y_val\n",
    "\n",
    "            metrics = {\n",
    "                'model': name,\n",
    "                'accuracy': accuracy_score(y_val_array, y_pred),\n",
    "                'precision': precision_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'recall': recall_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'f1_score': f1_score(y_val_array, y_pred, average='weighted', zero_division=0)\n",
    "            }\n",
    "            return pd.DataFrame([metrics])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in _evaluate_model for {name}: {str(e)}\")\n",
    "            return pd.DataFrame([{'model': name, 'error': str(e)}])\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, metric='f1_score', n_select=None):\n",
    "        evaluation_results = pd.DataFrame()\n",
    "\n",
    "        if self.use_gpu:\n",
    "            X_train_cudf = cudf.DataFrame.from_pandas(X_train)\n",
    "            y_train_cudf = cudf.Series(y_train)\n",
    "        else:\n",
    "            X_train_cudf = X_train\n",
    "            y_train_cudf = y_train\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training model: {name}\")\n",
    "            try:\n",
    "                if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                    model.fit(X_train_cudf, y_train_cudf)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                self.trained_models[name] = model\n",
    "\n",
    "                # Evaluate model\n",
    "                metrics_df = self._evaluate_model(name, model, X_val, y_val)\n",
    "                evaluation_results = pd.concat(\n",
    "                    [evaluation_results, metrics_df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        evaluation_results = evaluation_results.sort_values(\n",
    "            by=metric, ascending=False)\n",
    "        # Displaying results as HTML table\n",
    "        html_table = evaluation_results.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        # Select best models\n",
    "        if n_select:\n",
    "            top_models = evaluation_results.head(n_select)['model'].tolist()\n",
    "            self.best_model = [self.trained_models[name]\n",
    "                               for name in top_models]\n",
    "            self.best_model_name = top_models\n",
    "        else:\n",
    "            self.best_model_name = evaluation_results.iloc[0]['model']\n",
    "            self.best_model = self.trained_models[self.best_model_name]\n",
    "\n",
    "    def train_final(self, X_train, X_val, y_train, y_val, model=None):\n",
    "        \"\"\"\n",
    "        Train a model on the combined train and validation dataset.\n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - X_val: Validation features\n",
    "        - y_train: Training labels\n",
    "        - y_val: Validation labels\n",
    "        - model: (Optional) Specific model to train on combined data. If None, the first model from best_model will be used.\n",
    "        \"\"\"\n",
    "        # Combine train and validation datasets\n",
    "        X_combined = pd.concat([X_train, X_val], axis=0)\n",
    "        y_combined = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "        # If no model is provided, check best_model\n",
    "        if model is None:\n",
    "            if not self.best_model:\n",
    "                raise ValueError(\n",
    "                    \"Please train the models first using `train()` before calling `train_final()`.\")\n",
    "\n",
    "            # If best_model is a list of models, pick the first one\n",
    "            if isinstance(self.best_model, list):\n",
    "                # Take the first model if it's an array\n",
    "                model = self.best_model[0]\n",
    "                model_name = self.best_model_name[0]\n",
    "            else:\n",
    "                model = self.best_model\n",
    "                model_name = self.best_model_name\n",
    "\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "\n",
    "        print(f\"Training final model: {model_name}\")\n",
    "        model.fit(X_combined, y_combined)\n",
    "\n",
    "        # Store the trained final model\n",
    "        self.final_trained_model = model\n",
    "\n",
    "        return self.final_trained_model\n",
    "\n",
    "    def voting_ensemble(self, X_train, y_train, X_val, y_val, n_select=3, voting='soft'):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using voting ensemble.\")\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=selected_models, voting=voting)\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"VotingClassifier\", voting_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return voting_clf\n",
    "\n",
    "    def stacking_ensemble(self, X_train, y_train, X_val, y_val, meta_model=None, n_select=3):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using stacking ensemble.\")\n",
    "\n",
    "        if meta_model is None:\n",
    "            meta_model = LogisticRegression(random_state=self.random_state)\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=selected_models, final_estimator=meta_model)\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"StackingClassifier\", stacking_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return stacking_clf\n",
    "\n",
    "    def plot(self, model, X_val, y_val):\n",
    "        \"\"\"Plot confusion matrix, classification report, and ROC-AUC curve.\"\"\"\n",
    "\n",
    "        # Check if the model supports predict_proba (required for ROC-AUC)\n",
    "        supports_proba = hasattr(model, \"predict_proba\")\n",
    "\n",
    "        if self.use_gpu and isinstance(model, (cuLogisticRegression, cuKNeighborsClassifier, cuRandomForestClassifier, cuSVC)):\n",
    "            X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "            y_val_cudf = cudf.Series(y_val)\n",
    "            y_pred = model.predict(X_val_cudf).to_numpy()\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val_cudf).to_numpy()\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix for {model.__class__.__name__}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        # Classification Report\n",
    "        print(f'Classification Report for {model.__class__.__name__}:\\n')\n",
    "        print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "        # ROC-AUC Plot\n",
    "        if supports_proba:\n",
    "            # Check if it is a binary classification problem\n",
    "            if len(np.unique(y_val)) == 2:\n",
    "                fpr, tpr, _ = roc_curve(y_val, y_proba[:, 1])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                         label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'ROC Curve for {model.__class__.__name__}')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                # For multi-class classification, binarize the labels\n",
    "                y_val_bin = label_binarize(y_val, classes=np.unique(y_val))\n",
    "                n_classes = y_val_bin.shape[1]\n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "\n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(\n",
    "                        y_val_bin[:, i], y_proba[:, i])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "                # Plot ROC curve for each class\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                             label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(\n",
    "                    f'ROC Curve for {model.__class__.__name__} (multi-class)')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\n",
    "                f'ROC-AUC cannot be plotted for {model.__class__.__name__} as it does not support probability estimates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logreg\": True,\n",
    "    \"knn\": True,\n",
    "    \"dt\": True,\n",
    "    \"rf\": True,\n",
    "    \"xgb\": True,\n",
    "    \"lgbm\": True,\n",
    "    \"catboost\": True,\n",
    "    \"support_vector\": True,\n",
    "}\n",
    "# Initialize modelling with GPU enabled\n",
    "modelling = Modelling(config=config, random_state=42, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model dan memilih 3 model terbaik\n",
    "modelling.train(X_train, y_train, X_val, y_val, metric='f1_score', n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Voting ensemble dengan n_select=5 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "voting_model = modelling.voting_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Stacking ensemble dengan n_select=4 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "stacking_model = modelling.stacking_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation confussion matrix and classification report\n",
    "modelling.plot(modelling.best_model[0], X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = modelling.train_final(X_train, X_val, y_train, y_val)\n",
    "\n",
    "# prediction\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubes2-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
