{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 style=\"font-weight: bold;\">\n",
    "    Binary Classification from Tabular Data</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deskripsi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kompetisi ini, peserta diminta untuk memprediksi **< label >**. Data yang diberikan adalah : \n",
    "* **< feature 1 >** : **< feature1_description >**\n",
    "* **< feature 2 >** : **< feature2_description >**\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from class_reg_preprocessing import (\n",
    "    FeatureOutliersHandling,\n",
    "    FeatureImputer,\n",
    "    FeatureResampling,\n",
    "    FeatureLabelEncoder,\n",
    "    FeatureDiscretizer,\n",
    "    FeatureRareCategoriesGrouping,\n",
    "    FeaturePolynomialAdder,\n",
    "    FeaturePowerTransformer,\n",
    "    FeatureGroupingNumeric,\n",
    "    FeatureDimensionReducer,\n",
    "    FeatureEncoder,\n",
    "    FeatureScaler,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_date</th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/1/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/2/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/3/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/4/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/5/2021</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>3/31/2021 0:00</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4/1/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>4/2/2021 0:00</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>4/3/2021 0:00</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>4/4/2021 0:00</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.3500</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4048 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           read_date  interval_1  interval_2  interval_3  interval_4  \\\n",
       "0           3/1/2021      0.0625      0.0500      0.0687      0.0750   \n",
       "1           3/2/2021      0.0625      0.0500      0.0687      0.0625   \n",
       "2           3/3/2021      0.0625      0.0687      0.0500      0.0562   \n",
       "3           3/4/2021      0.0625      0.0625      0.0687      0.0500   \n",
       "4           3/5/2021      0.0625      0.0625      0.0500      0.0625   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "4043  3/31/2021 0:00      0.2125      0.2000      0.1625      0.1750   \n",
       "4044   4/1/2021 0:00      0.1625      0.1625      0.1500      0.1500   \n",
       "4045   4/2/2021 0:00      0.1625      0.2000      0.2125      0.1625   \n",
       "4046   4/3/2021 0:00      0.2250      0.2250      0.1625      0.1750   \n",
       "4047   4/4/2021 0:00      0.2000      0.1625      0.1625      0.2000   \n",
       "\n",
       "      interval_5  interval_6  interval_7  interval_8  interval_9  ...  \\\n",
       "0         0.0687      0.0500      0.0625      0.0687      0.0687  ...   \n",
       "1         0.0625      0.0562      0.0562      0.0625      0.0687  ...   \n",
       "2         0.0687      0.0625      0.0625      0.0625      0.0500  ...   \n",
       "3         0.0562      0.0625      0.0625      0.0625      0.0562  ...   \n",
       "4         0.0687      0.0625      0.0687      0.0562      0.0500  ...   \n",
       "...          ...         ...         ...         ...         ...  ...   \n",
       "4043      0.2375      0.2125      0.1875      0.1750      0.2000  ...   \n",
       "4044      0.2000      0.1750      0.1625      0.1625      0.1500  ...   \n",
       "4045      0.1625      0.1375      0.1500      0.1250      0.1875  ...   \n",
       "4046      0.1750      0.1500      0.1500      0.2125      0.1625  ...   \n",
       "4047      0.1500      0.1500      0.1750      0.1750      0.1375  ...   \n",
       "\n",
       "      interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "0          0.0812       0.0687       0.0687       0.0562       0.0562   \n",
       "1          0.1375       0.0750       0.0687       0.0625       0.0625   \n",
       "2          0.1875       0.1062       0.0750       0.0687       0.0687   \n",
       "3          0.1125       0.0875       0.0687       0.0625       0.0562   \n",
       "4          0.0812       0.0562       0.0687       0.0625       0.0625   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4043       0.3375       0.3875       0.3375       0.3875       0.2500   \n",
       "4044       0.2375       0.2000       0.2125       0.2000       0.2000   \n",
       "4045       0.2500       0.2750       0.3750       0.3375       0.3250   \n",
       "4046       0.3375       0.4000       0.3500       0.2625       0.4000   \n",
       "4047       0.5250       0.4125       0.4000       0.4500       0.3625   \n",
       "\n",
       "      interval_46  interval_47  interval_48  id  label  \n",
       "0          0.0687       0.0687       0.0625   1      1  \n",
       "1          0.0562       0.0625       0.0625   1      1  \n",
       "2          0.0625       0.0562       0.0562   1      1  \n",
       "3          0.0625       0.0625       0.0687   1      1  \n",
       "4          0.0625       0.0562       0.0500   1      1  \n",
       "...           ...          ...          ...  ..    ...  \n",
       "4043       0.5125       0.4750       0.2000  57      0  \n",
       "4044       0.2875       0.1875       0.2250  57      0  \n",
       "4045       0.2625       0.3000       0.3500  57      0  \n",
       "4046       0.3375       0.8375       0.6625  57      0  \n",
       "4047       0.6500       1.3500       0.7875  57      0  \n",
       "\n",
       "[4048 rows x 51 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: define initial dataframes\n",
    "initial_df = pd.read_csv(f'{data_path}/EV_data.csv')\n",
    "# -----------------------------------\n",
    "\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: define test dataframe\n",
    "# test_features_df = pd.read_csv(f'{data_path}/test_features.csv')\n",
    "\n",
    "# submisssion_ids = test_features_df['ID']\n",
    "\n",
    "# test_features_df = test_features_df.drop(columns=['ID'])\n",
    "# # -------------------------------------\n",
    "\n",
    "# test_features_df = test_features_df.reindex(sorted(test_features_df.columns), axis=1)\n",
    "\n",
    "# test_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Target and Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define which columns are target labels\n",
    "label = 'label'\n",
    "# -----------------------------------\n",
    "# TODO: define which columns are categorical and which are numerical features\n",
    "categorical_features = ['id']\n",
    "\n",
    "# get all columns with float64 and int64 data types\n",
    "numerical_features = initial_df.select_dtypes(include=['float64']).columns\n",
    "# -----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Unnecessary Columns [TENTATIVE]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define columns to drop\n",
    "columns_to_drop = ['read_date']\n",
    "# -----------------------------------\n",
    "\n",
    "categorical_features = [col for col in categorical_features if col not in columns_to_drop]\n",
    "numerical_features = [col for col in numerical_features if col not in columns_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for initial data before removing duplicates: 4048\n",
      "Row count for initial data after removing duplicates: 4048\n"
     ]
    }
   ],
   "source": [
    "print('Row count for initial data before removing duplicates:', len(initial_df))\n",
    "initial_df.drop_duplicates(inplace=True)\n",
    "print('Row count for initial data after removing duplicates:', len(initial_df))\n",
    "initial_df.reset_index(drop=True, inplace=True) # Reset the index after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = initial_df.drop(columns=columns_to_drop)\n",
    "# test_features_df = test_features_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Wrong Value to NaN [Tentative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_values = '5'\n",
    "\n",
    "# initial_df['pendidikan'] = initial_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# initial_df['status_pernikahan'] = initial_df['status_pernikahan'].replace(wrong_values, np.nan)\n",
    "\n",
    "# test_features_df['pendidikan'] = test_features_df['pendidikan'].replace(wrong_values, np.nan)\n",
    "# test_features_df['status_pernikahan'] = test_features_df['status_pernikahan'].replace(wrong_values, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check Similarity Columns between Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_cols(df1: pd.DataFrame, df2: pd.DataFrame, label: str):\n",
    "    \"\"\"\n",
    "    Function to check if two DataFrames have the same columns, excluding the label column if it exists.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1: First DataFrame\n",
    "    - df2: Second DataFrame\n",
    "    - label: The name of the label column to exclude from the comparison (default is 'label').\n",
    "    \n",
    "    Returns:\n",
    "    - Boolean value indicating whether the columns are the same, excluding the label column\n",
    "    \"\"\"\n",
    "    # Exclude the label column if it exists in either DataFrame\n",
    "    df1_cols = df1.columns.drop(label) if label in df1.columns else df1.columns\n",
    "    df2_cols = df2.columns.drop(label) if label in df2.columns else df2.columns\n",
    "\n",
    "    # Compare the remaining columns\n",
    "    return df1_cols.equals(df2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Initial and test features have the same columns:', is_same_cols(initial_df, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert read_date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial_df['read_date'] = pd.to_datetime(initial_df['read_date'], format='%m/%d/%Y')\n",
    "\n",
    "# initial_df['read_date'] = initial_df['read_date'].str.replace(' 0:00', '')\n",
    "# initial_df['read_date'] = pd.to_datetime(initial_df['read_date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_df['day_of_week_num'] = initial_df['read_date'].dt.day_of_week\n",
    "# initial_df['day_of_month'] = initial_df['read_date'].dt.day\n",
    "# initial_df['month'] = initial_df['read_date'].dt.month\n",
    "# initial_df.drop(columns=['read_date'], inplace=True)\n",
    "# initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = initial_df.drop(columns=[label])\n",
    "y = initial_df[label]\n",
    "\n",
    "# X_test = test_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 4048\n",
      "Jumlah data train: 3238\n",
      "Jumlah data validasi: 810\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Jumlah data:\", len(initial_df))\n",
    "print(\"Jumlah data train:\", len(X_train))\n",
    "print(\"Jumlah data validasi:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and X_val have the same columns: True\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train and X_val have the same columns:\", is_same_cols(X_train, X_val, label))\n",
    "# print(\"X_test has the same columns as X_train:\", is_same_cols(X_train, test_features_df, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Outliers Value to NaN [TENTATIVE: Based on EDA Boxplot]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_handler_iforest = FeatureOutliersHandling(\n",
    "    numerical_features=numerical_features,\n",
    "    contamination=0.05, \n",
    "    outlier_method='iforest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iforest.fit_transform(X_train)\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outlier : IQR-ZScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_handler_iqr_zscore = FeatureOutliersHandling(\n",
    "#     numerical_features=numerical_features, \n",
    "#     contamination=0.05, \n",
    "#     outlier_method='iqr-zscore'\n",
    "# )\n",
    "\n",
    "# outlier_handler_iqr_zscore.plot_boxplots_for_numerical_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = outlier_handler_iqr_zscore.fit_transform(X_train, numerical_features_to_handle=numerical_features)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Impute Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = FeatureImputer(\n",
    "    numerical_features=numerical_features,\n",
    "    categorical_features=categorical_features,\n",
    "    int_num_features=numerical_features, # depends on the dataset\n",
    "    imputer_type='iterative',\n",
    "    num_strategy='mean',\n",
    "    cat_strategy='most_frequent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval_1     0\n",
       "interval_2     0\n",
       "interval_3     0\n",
       "interval_4     0\n",
       "interval_5     0\n",
       "interval_6     0\n",
       "interval_7     0\n",
       "interval_8     0\n",
       "interval_9     0\n",
       "interval_10    0\n",
       "interval_11    0\n",
       "interval_12    0\n",
       "interval_13    0\n",
       "interval_14    0\n",
       "interval_15    0\n",
       "interval_16    0\n",
       "interval_17    0\n",
       "interval_18    0\n",
       "interval_19    0\n",
       "interval_20    0\n",
       "interval_21    0\n",
       "interval_22    0\n",
       "interval_23    0\n",
       "interval_24    0\n",
       "interval_25    0\n",
       "interval_26    0\n",
       "interval_27    0\n",
       "interval_28    0\n",
       "interval_29    0\n",
       "interval_30    0\n",
       "interval_31    0\n",
       "interval_32    0\n",
       "interval_33    0\n",
       "interval_34    0\n",
       "interval_35    0\n",
       "interval_36    0\n",
       "interval_37    0\n",
       "interval_38    0\n",
       "interval_39    0\n",
       "interval_40    0\n",
       "interval_41    0\n",
       "interval_42    0\n",
       "interval_43    0\n",
       "interval_44    0\n",
       "interval_45    0\n",
       "interval_46    0\n",
       "interval_47    0\n",
       "interval_48    0\n",
       "id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = imputer.fit_transform(X_train)\n",
    "# X_val = imputer.transform(X_val)\n",
    "# # X_test = imputer.transform(X_test)\n",
    "\n",
    "# X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resampling [TENTATIVE: Based on Label Distribution]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = {1: 786, 2: 786}\n",
    "\n",
    "# resampler = FeatureResampling(\n",
    "#     resampling_method='oversampling',\n",
    "#     categorical_features=categorical_features,\n",
    "#     sampling_strategy=sampling_strategy,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Sebelum Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = resampler.fit_transform(X_train, y_train)\n",
    "\n",
    "# resampler.plot_class_count(y_train, title=\"Distribusi Kelas Setelah Oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Label [TENTATIVE: If Label is Categorical Object]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = FeatureLabelEncoder()\n",
    "\n",
    "# y_train = label_encoder.fit_transform(y_train)\n",
    "# y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# label_encoder.get_encoding_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Binning [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = FeatureDiscretizer(\n",
    "    n_bins=5,\n",
    "    encode='ordinal',\n",
    "    strategy='uniform',\n",
    "    numerical_features_to_discretize=['tahun_kelahiran']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = discretizer.fit_transform(X_train)\n",
    "# X_val = discretizer.transform(X_val)\n",
    "# X_test = discretizer.transform(X_test)\n",
    "# discretizer.get_bin_edges()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical Features : Rare Categories Grouping [OPTIONAL: If Column has Rare Categories]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features_to_group = ['status_pernikahan', 'pendidikan']\n",
    "\n",
    "# rare_grouping = FeatureRareCategoriesGrouping(\n",
    "#     categorical_features=categorical_features_to_group,\n",
    "#     threshold=0.1,\n",
    "#     rare_label='Rare'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} before rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = rare_grouping.fit_transform(X_train)\n",
    "# X_val = rare_grouping.transform(X_val)\n",
    "# X_test = rare_grouping.transform(X_test)\n",
    "\n",
    "# for feature in categorical_features_to_group:\n",
    "#     print(f\"Value counts for {feature} after rare category grouping:\")\n",
    "#     print(X_train[feature].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Polynomial Features [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_poly = [\n",
    "#     'pembelian_diskon',\n",
    "#     'pembelian_toko',\n",
    "#     'pembelian_web'\n",
    "# ]\n",
    "\n",
    "# poly_features_adder = FeaturePolynomialAdder(\n",
    "#     degree=2,\n",
    "#     interaction_only=False,\n",
    "#     include_bias=False,\n",
    "#     columns=columns_to_poly\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = poly_features_adder.fit_transform(X_train)\n",
    "# X_val = poly_features_adder.transform(X_val)\n",
    "# X_test = poly_features_adder.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Power Transform [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_transform = [\n",
    "#     'belanja_buah',\n",
    "#     'belanja_daging',\n",
    "#     'belanja_ikan',\n",
    "#     'belanja_kue',\n",
    "# ]\n",
    "\n",
    "# # Inisialisasi transformer\n",
    "# power_transformer = FeaturePowerTransformer(\n",
    "#     method='yeo-johnson',\n",
    "#     standardize=True,\n",
    "#     columns=numerical_features_to_transform\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data sebelum transformasi\n",
    "# X_train_before = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Fit dan transform data\n",
    "# X_train = power_transformer.fit_transform(X_train)\n",
    "# X_val = power_transformer.transform(X_val)\n",
    "# X_test = power_transformer.transform(X_test)\n",
    "\n",
    "# # Data setelah transformasi\n",
    "# X_train_after = X_train[numerical_features_to_transform]\n",
    "\n",
    "# # Plot distribusi sebelum dan sesudah transformasi\n",
    "# power_transformer.plot_kde_hist_before_after(X_train_before, X_train_after)\n",
    "\n",
    "# # Dapatkan nilai lambda untuk setiap fitur\n",
    "# print(\"Lambda values for power transformation:\")\n",
    "# print(power_transformer.get_lambdas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Grouping (min,max,mean,median,std) [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features_to_grouping = [\n",
    "#     'belanja_buah', \n",
    "#     'belanja_daging', \n",
    "#     'belanja_ikan', \n",
    "#     'belanja_kue'\n",
    "# ]\n",
    "\n",
    "# grouping_transformer = FeatureGroupingNumeric(\n",
    "#     numerical_features_to_grouping=numerical_features_to_grouping,\n",
    "#     aggregations=['min', 'max', 'mean', 'median', 'std'],\n",
    "#     columns_name='belanja'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = grouping_transformer.fit_transform(X_train)\n",
    "# X_val = grouping_transformer.transform(X_val)\n",
    "# X_test = grouping_transformer.transform(X_test)\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numerical Features : Dimensionality Reduction [OPTIONAL: If Necessary]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_pca = ['belanja_buah','belanja_daging','belanja_ikan','belanja_kue']\n",
    "n_components = 4\n",
    "\n",
    "reducer = FeatureDimensionReducer(\n",
    "    method='pca',\n",
    "    n_components=n_components,\n",
    "    numeric_features_to_reduce=numeric_features_pca,\n",
    "    column_names='belanja_pca'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = reducer.fit_transform(X_train) \n",
    "\n",
    "# print(f\"Explained variance ratio for {n_components} components:\\n\", reducer.get_variance_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_pca = reducer.transform(X_val)\n",
    "# # X_test_pca = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>interval_10</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_40</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>1.3375</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>1.1510</td>\n",
       "      <td>1.5080</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.6187</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>3.8187</td>\n",
       "      <td>3.9437</td>\n",
       "      <td>3.7312</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>3.8812</td>\n",
       "      <td>3.7625</td>\n",
       "      <td>3.7937</td>\n",
       "      <td>3.6812</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3238 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      interval_1  interval_2  interval_3  interval_4  interval_5  interval_6  \\\n",
       "4004      1.0625      0.6750      0.9875      1.0000      0.8250      0.7125   \n",
       "3240      0.1500      0.1500      0.1437      0.1437      0.1500      0.1437   \n",
       "2838      0.0630      0.0620      0.0620      0.0610      0.0620      0.0630   \n",
       "3426      0.0940      0.0970      0.0820      0.0890      0.0960      0.0820   \n",
       "3929      0.2090      0.1850      0.2950      0.1570      0.1270      0.1670   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "437       0.0000      0.0062      0.0000      0.0000      0.0000      0.0062   \n",
       "1047      0.0375      0.0312      0.0250      0.0437      0.0250      0.0250   \n",
       "641       0.6187      0.5062      0.4500      0.4625      0.4812      0.4750   \n",
       "379       0.0875      0.0937      0.1000      0.1000      0.0937      0.1187   \n",
       "465       0.1250      0.1187      0.1312      0.1437      0.1375      0.1312   \n",
       "\n",
       "      interval_7  interval_8  interval_9  interval_10  ...  interval_40  \\\n",
       "4004      0.8000      0.9625      1.0000       0.9875  ...       0.7625   \n",
       "3240      0.1437      0.1500      0.1187       0.4750  ...       0.1812   \n",
       "2838      0.0650      0.0650      0.0630       0.0640  ...       0.0680   \n",
       "3426      0.0980      0.0920      0.0760       0.0980  ...       0.1920   \n",
       "3929      0.1430      0.1440      0.1610       0.1220  ...       0.7390   \n",
       "...          ...         ...         ...          ...  ...          ...   \n",
       "437       0.0000      0.0000      0.0062       0.0000  ...       0.0000   \n",
       "1047      0.0437      0.0250      0.0250       0.0437  ...       0.4312   \n",
       "641       0.4937      0.4625      0.5937       0.4875  ...       3.8750   \n",
       "379       0.1562      0.1187      0.1250       0.0875  ...       0.1750   \n",
       "465       0.1125      0.1250      0.1437       0.1437  ...       0.4250   \n",
       "\n",
       "      interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "4004       0.7375       0.9250       0.7625       0.7875       1.0125   \n",
       "3240       0.1750       0.1312       0.2437       0.1500       0.1437   \n",
       "2838       0.0800       0.0610       0.0610       0.0600       0.0550   \n",
       "3426       0.1610       0.1740       0.1130       0.0970       0.1060   \n",
       "3929       0.7530       0.7180       0.5670       0.5520       0.3750   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "437        0.0000       0.0062       0.0000       0.0000       0.0062   \n",
       "1047       0.3625       0.1000       0.1187       0.0750       0.1125   \n",
       "641        3.8187       3.9437       3.7312       3.8000       3.8812   \n",
       "379        0.1500       0.2000       0.3187       0.2937       0.1187   \n",
       "465        0.2750       0.2812       0.2625       0.2437       0.2187   \n",
       "\n",
       "      interval_46  interval_47  interval_48  id  \n",
       "4004       1.3375       0.9750       0.8000  57  \n",
       "3240       0.1500       0.1500       0.2312  80  \n",
       "2838       0.0570       0.0570       0.0530  77  \n",
       "3426       0.1180       1.1510       1.5080  71  \n",
       "3929       0.1820       0.1520       0.1640  83  \n",
       "...           ...          ...          ...  ..  \n",
       "437        0.0000       0.0000       0.0000  32  \n",
       "1047       0.0375       0.0187       0.0500  23  \n",
       "641        3.7625       3.7937       3.6812  36  \n",
       "379        0.1125       0.1187       0.1062  31  \n",
       "465        0.2375       0.1687       0.1125  33  \n",
       "\n",
       "[3238 rows x 49 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features_lda = ['pembelian_diskon','pembelian_toko','pembelian_web']\n",
    "# n_components = 2\n",
    "\n",
    "# reducer = FeatureDimensionReducer(\n",
    "#     method='lda',\n",
    "#     n_components=n_components,\n",
    "#     numeric_features_to_reduce=numeric_features_lda,\n",
    "#     column_names='pembelian_lda'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = reducer.fit_transform(X_train, y_train)\n",
    "# X_val_lda = reducer.transform(X_val)\n",
    "# X_test_lda = reducer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Define the ordinal features from the categorical features\n",
    "# ordinal_features_dict = {\n",
    "#     # 'pendidikan': ['SMP', 'SMA', 'Sarjana', 'Magister', 'Doktor'],\n",
    "#     'status_pernikahan': ['Rencana Menikah', 'Menikah', 'Sendiri', 'Cerai', 'Cerai Mati']\n",
    "# }\n",
    "# # -----------------------------------\n",
    "\n",
    "# # Define the nominal categorical features for one-hot encoding\n",
    "# one_hot_features = ['pendidikan']\n",
    "\n",
    "# encoder = FeatureEncoder(\n",
    "#     ordinal_features_dict=ordinal_features_dict,\n",
    "#     one_hot_features=one_hot_features\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3238 entries, 4004 to 465\n",
      "Data columns (total 49 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   interval_1   3238 non-null   float64\n",
      " 1   interval_2   3238 non-null   float64\n",
      " 2   interval_3   3238 non-null   float64\n",
      " 3   interval_4   3238 non-null   float64\n",
      " 4   interval_5   3238 non-null   float64\n",
      " 5   interval_6   3238 non-null   float64\n",
      " 6   interval_7   3238 non-null   float64\n",
      " 7   interval_8   3238 non-null   float64\n",
      " 8   interval_9   3238 non-null   float64\n",
      " 9   interval_10  3238 non-null   float64\n",
      " 10  interval_11  3238 non-null   float64\n",
      " 11  interval_12  3238 non-null   float64\n",
      " 12  interval_13  3238 non-null   float64\n",
      " 13  interval_14  3238 non-null   float64\n",
      " 14  interval_15  3238 non-null   float64\n",
      " 15  interval_16  3238 non-null   float64\n",
      " 16  interval_17  3238 non-null   float64\n",
      " 17  interval_18  3238 non-null   float64\n",
      " 18  interval_19  3238 non-null   float64\n",
      " 19  interval_20  3238 non-null   float64\n",
      " 20  interval_21  3238 non-null   float64\n",
      " 21  interval_22  3238 non-null   float64\n",
      " 22  interval_23  3238 non-null   float64\n",
      " 23  interval_24  3238 non-null   float64\n",
      " 24  interval_25  3238 non-null   float64\n",
      " 25  interval_26  3238 non-null   float64\n",
      " 26  interval_27  3238 non-null   float64\n",
      " 27  interval_28  3238 non-null   float64\n",
      " 28  interval_29  3238 non-null   float64\n",
      " 29  interval_30  3238 non-null   float64\n",
      " 30  interval_31  3238 non-null   float64\n",
      " 31  interval_32  3238 non-null   float64\n",
      " 32  interval_33  3238 non-null   float64\n",
      " 33  interval_34  3238 non-null   float64\n",
      " 34  interval_35  3238 non-null   float64\n",
      " 35  interval_36  3238 non-null   float64\n",
      " 36  interval_37  3238 non-null   float64\n",
      " 37  interval_38  3238 non-null   float64\n",
      " 38  interval_39  3238 non-null   float64\n",
      " 39  interval_40  3238 non-null   float64\n",
      " 40  interval_41  3238 non-null   float64\n",
      " 41  interval_42  3238 non-null   float64\n",
      " 42  interval_43  3238 non-null   float64\n",
      " 43  interval_44  3238 non-null   float64\n",
      " 44  interval_45  3238 non-null   float64\n",
      " 45  interval_46  3238 non-null   float64\n",
      " 46  interval_47  3238 non-null   float64\n",
      " 47  interval_48  3238 non-null   float64\n",
      " 48  id           3238 non-null   int64  \n",
      "dtypes: float64(48), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = encoder.fit_transform(X_train)\n",
    "# X_val = encoder.transform(X_val)\n",
    "# X_test = encoder.transform(X_test)\n",
    "\n",
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interval_1</th>\n",
       "      <th>interval_2</th>\n",
       "      <th>interval_3</th>\n",
       "      <th>interval_4</th>\n",
       "      <th>interval_5</th>\n",
       "      <th>interval_6</th>\n",
       "      <th>interval_7</th>\n",
       "      <th>interval_8</th>\n",
       "      <th>interval_9</th>\n",
       "      <th>interval_10</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_40</th>\n",
       "      <th>interval_41</th>\n",
       "      <th>interval_42</th>\n",
       "      <th>interval_43</th>\n",
       "      <th>interval_44</th>\n",
       "      <th>interval_45</th>\n",
       "      <th>interval_46</th>\n",
       "      <th>interval_47</th>\n",
       "      <th>interval_48</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>1.3375</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>1.1510</td>\n",
       "      <td>1.5080</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.6187</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>3.8187</td>\n",
       "      <td>3.9437</td>\n",
       "      <td>3.7312</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>3.8812</td>\n",
       "      <td>3.7625</td>\n",
       "      <td>3.7937</td>\n",
       "      <td>3.6812</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3238 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      interval_1  interval_2  interval_3  interval_4  interval_5  interval_6  \\\n",
       "4004      1.0625      0.6750      0.9875      1.0000      0.8250      0.7125   \n",
       "3240      0.1500      0.1500      0.1437      0.1437      0.1500      0.1437   \n",
       "2838      0.0630      0.0620      0.0620      0.0610      0.0620      0.0630   \n",
       "3426      0.0940      0.0970      0.0820      0.0890      0.0960      0.0820   \n",
       "3929      0.2090      0.1850      0.2950      0.1570      0.1270      0.1670   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "437       0.0000      0.0062      0.0000      0.0000      0.0000      0.0062   \n",
       "1047      0.0375      0.0312      0.0250      0.0437      0.0250      0.0250   \n",
       "641       0.6187      0.5062      0.4500      0.4625      0.4812      0.4750   \n",
       "379       0.0875      0.0937      0.1000      0.1000      0.0937      0.1187   \n",
       "465       0.1250      0.1187      0.1312      0.1437      0.1375      0.1312   \n",
       "\n",
       "      interval_7  interval_8  interval_9  interval_10  ...  interval_40  \\\n",
       "4004      0.8000      0.9625      1.0000       0.9875  ...       0.7625   \n",
       "3240      0.1437      0.1500      0.1187       0.4750  ...       0.1812   \n",
       "2838      0.0650      0.0650      0.0630       0.0640  ...       0.0680   \n",
       "3426      0.0980      0.0920      0.0760       0.0980  ...       0.1920   \n",
       "3929      0.1430      0.1440      0.1610       0.1220  ...       0.7390   \n",
       "...          ...         ...         ...          ...  ...          ...   \n",
       "437       0.0000      0.0000      0.0062       0.0000  ...       0.0000   \n",
       "1047      0.0437      0.0250      0.0250       0.0437  ...       0.4312   \n",
       "641       0.4937      0.4625      0.5937       0.4875  ...       3.8750   \n",
       "379       0.1562      0.1187      0.1250       0.0875  ...       0.1750   \n",
       "465       0.1125      0.1250      0.1437       0.1437  ...       0.4250   \n",
       "\n",
       "      interval_41  interval_42  interval_43  interval_44  interval_45  \\\n",
       "4004       0.7375       0.9250       0.7625       0.7875       1.0125   \n",
       "3240       0.1750       0.1312       0.2437       0.1500       0.1437   \n",
       "2838       0.0800       0.0610       0.0610       0.0600       0.0550   \n",
       "3426       0.1610       0.1740       0.1130       0.0970       0.1060   \n",
       "3929       0.7530       0.7180       0.5670       0.5520       0.3750   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "437        0.0000       0.0062       0.0000       0.0000       0.0062   \n",
       "1047       0.3625       0.1000       0.1187       0.0750       0.1125   \n",
       "641        3.8187       3.9437       3.7312       3.8000       3.8812   \n",
       "379        0.1500       0.2000       0.3187       0.2937       0.1187   \n",
       "465        0.2750       0.2812       0.2625       0.2437       0.2187   \n",
       "\n",
       "      interval_46  interval_47  interval_48  id  \n",
       "4004       1.3375       0.9750       0.8000  57  \n",
       "3240       0.1500       0.1500       0.2312  80  \n",
       "2838       0.0570       0.0570       0.0530  77  \n",
       "3426       0.1180       1.1510       1.5080  71  \n",
       "3929       0.1820       0.1520       0.1640  83  \n",
       "...           ...          ...          ...  ..  \n",
       "437        0.0000       0.0000       0.0000  32  \n",
       "1047       0.0375       0.0187       0.0500  23  \n",
       "641        3.7625       3.7937       3.6812  36  \n",
       "379        0.1125       0.1187       0.1062  31  \n",
       "465        0.2375       0.1687       0.1125  33  \n",
       "\n",
       "[3238 rows x 49 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler if the data is normally distributed, otherwise use MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = FeatureScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# # X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_features, non_normal_features = scaler.get_scaler_columns()\n",
    "\n",
    "# print(\"Normal Features:\", normal_features)\n",
    "# print(\"Non-Normal Features:\", non_normal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, lr=0.001, n_iters=200):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions-y)\n",
    "            \n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        class_pred = [0 if y<=0.5 else 1 for y in y_pred]\n",
    "        return class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(lr=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       405\n",
      "           1       0.86      0.82      0.84       405\n",
      "\n",
      "    accuracy                           0.84       810\n",
      "   macro avg       0.84      0.84      0.84       810\n",
      "weighted avg       0.84      0.84      0.84       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression \u001b[38;5;28;01mas\u001b[39;00m cuLogisticRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier \u001b[38;5;28;01mas\u001b[39;00m cuKNeighborsClassifier\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier \u001b[38;5;28;01mas\u001b[39;00m cuRandomForestClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from cuml.linear_model import LogisticRegression as cuLogisticRegression\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNeighborsClassifier\n",
    "from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\n",
    "from cuml.svm import SVC as cuSVC  # cuML GPU-based SVC\n",
    "import cudf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC  # sklearn SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class Modelling:\n",
    "    def __init__(self, config, random_state=42, use_gpu=False):\n",
    "        self.config = config\n",
    "        self.random_state = random_state\n",
    "        self.use_gpu = use_gpu\n",
    "        self.models = self._initialize_models()\n",
    "        self.trained_models = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.final_trained_model = None\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        models = {}\n",
    "        if self.config.get(\"logreg\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based Logistic Regression\n",
    "                models[\"logreg\"] = cuLogisticRegression()\n",
    "            else:\n",
    "                models[\"logreg\"] = LogisticRegression(\n",
    "                    random_state=self.random_state)\n",
    "\n",
    "        if self.config.get(\"knn\"):\n",
    "            if self.use_gpu:\n",
    "                # GPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = cuKNeighborsClassifier()\n",
    "            else:\n",
    "                # CPU-based KNeighborsClassifier\n",
    "                models[\"knn\"] = KNeighborsClassifier()\n",
    "\n",
    "        if self.config.get(\"dt\"):\n",
    "            models[\"dt\"] = DecisionTreeClassifier(\n",
    "                random_state=self.random_state)  # Always use sklearn DecisionTree\n",
    "\n",
    "        if self.config.get(\"rf\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"rf\"] = cuRandomForestClassifier(\n",
    "                    random_state=self.random_state)  # GPU-based RandomForest\n",
    "            else:\n",
    "                models[\"rf\"] = RandomForestClassifier(\n",
    "                    random_state=self.random_state)  # CPU-based RandomForest\n",
    "\n",
    "        if self.config.get(\"xgb\"):\n",
    "            models[\"xgb\"] = XGBClassifier(\n",
    "                use_label_encoder=False,\n",
    "                random_state=self.random_state,\n",
    "                tree_method='gpu_hist' if self.use_gpu else 'hist',  # GPU usage for XGBoost\n",
    "                predictor='gpu_predictor' if self.use_gpu else 'cpu_predictor'\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"lgbm\"):\n",
    "            models[\"lgbm\"] = LGBMClassifier(\n",
    "                random_state=self.random_state,\n",
    "                device='cpu'  # Force CPU usage for LightGBM due to OpenCL issues\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"catboost\"):\n",
    "            models[\"catboost\"] = CatBoostClassifier(\n",
    "                silent=True,\n",
    "                random_state=self.random_state,\n",
    "                task_type='GPU' if self.use_gpu else 'CPU'  # GPU usage for CatBoost\n",
    "            )\n",
    "\n",
    "        if self.config.get(\"support_vector\"):\n",
    "            if self.use_gpu:\n",
    "                models[\"support_vector\"] = cuSVC()  # GPU-based SVC from cuML\n",
    "            else:\n",
    "                models[\"support_vector\"] = SVC(\n",
    "                    probability=True, random_state=self.random_state)  # CPU-based SVC\n",
    "\n",
    "        return models\n",
    "\n",
    "    def _evaluate_model(self, name, model, X_val, y_val):\n",
    "        try:\n",
    "            if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                # Convert input to cuDF for cuML models\n",
    "                X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "                y_val_cudf = cudf.Series(y_val)\n",
    "\n",
    "                print(f\"X_val_cudf dtypes: {X_val_cudf.dtypes}\")\n",
    "                print(f\"y_val_cudf dtype: {y_val_cudf.dtype}\")\n",
    "\n",
    "                y_pred = model.predict(X_val_cudf)\n",
    "                print(f\"y_pred type: {type(y_pred)}, dtype: {y_pred.dtype}\")\n",
    "\n",
    "                # Convert to NumPy arrays for compatibility with scikit-learn metrics\n",
    "                y_pred = y_pred.to_numpy()\n",
    "                y_val_array = y_val_cudf.to_numpy()\n",
    "            else:\n",
    "                # For sklearn models\n",
    "                y_pred = model.predict(X_val)\n",
    "                y_val_array = y_val\n",
    "\n",
    "            metrics = {\n",
    "                'model': name,\n",
    "                'accuracy': accuracy_score(y_val_array, y_pred),\n",
    "                'precision': precision_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'recall': recall_score(y_val_array, y_pred, average='weighted', zero_division=0),\n",
    "                'f1_score': f1_score(y_val_array, y_pred, average='weighted', zero_division=0)\n",
    "            }\n",
    "            return pd.DataFrame([metrics])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in _evaluate_model for {name}: {str(e)}\")\n",
    "            return pd.DataFrame([{'model': name, 'error': str(e)}])\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, metric='f1_score', n_select=None):\n",
    "        evaluation_results = pd.DataFrame()\n",
    "\n",
    "        if self.use_gpu:\n",
    "            X_train_cudf = cudf.DataFrame.from_pandas(X_train)\n",
    "            y_train_cudf = cudf.Series(y_train)\n",
    "        else:\n",
    "            X_train_cudf = X_train\n",
    "            y_train_cudf = y_train\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training model: {name}\")\n",
    "            try:\n",
    "                if self.use_gpu and name in ['logreg', 'knn', 'rf', 'support_vector']:\n",
    "                    model.fit(X_train_cudf, y_train_cudf)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                self.trained_models[name] = model\n",
    "\n",
    "                # Evaluate model\n",
    "                metrics_df = self._evaluate_model(name, model, X_val, y_val)\n",
    "                evaluation_results = pd.concat(\n",
    "                    [evaluation_results, metrics_df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error training {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        evaluation_results = evaluation_results.sort_values(\n",
    "            by=metric, ascending=False)\n",
    "        # Displaying results as HTML table\n",
    "        html_table = evaluation_results.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        # Select best models\n",
    "        if n_select:\n",
    "            top_models = evaluation_results.head(n_select)['model'].tolist()\n",
    "            self.best_model = [self.trained_models[name]\n",
    "                               for name in top_models]\n",
    "            self.best_model_name = top_models\n",
    "        else:\n",
    "            self.best_model_name = evaluation_results.iloc[0]['model']\n",
    "            self.best_model = self.trained_models[self.best_model_name]\n",
    "\n",
    "    def train_final(self, X_train, X_val, y_train, y_val, model=None):\n",
    "        \"\"\"\n",
    "        Train a model on the combined train and validation dataset.\n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - X_val: Validation features\n",
    "        - y_train: Training labels\n",
    "        - y_val: Validation labels\n",
    "        - model: (Optional) Specific model to train on combined data. If None, the first model from best_model will be used.\n",
    "        \"\"\"\n",
    "        # Combine train and validation datasets\n",
    "        X_combined = pd.concat([X_train, X_val], axis=0)\n",
    "        y_combined = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "        # If no model is provided, check best_model\n",
    "        if model is None:\n",
    "            if not self.best_model:\n",
    "                raise ValueError(\n",
    "                    \"Please train the models first using `train()` before calling `train_final()`.\")\n",
    "\n",
    "            # If best_model is a list of models, pick the first one\n",
    "            if isinstance(self.best_model, list):\n",
    "                # Take the first model if it's an array\n",
    "                model = self.best_model[0]\n",
    "                model_name = self.best_model_name[0]\n",
    "            else:\n",
    "                model = self.best_model\n",
    "                model_name = self.best_model_name\n",
    "\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "\n",
    "        print(f\"Training final model: {model_name}\")\n",
    "        model.fit(X_combined, y_combined)\n",
    "\n",
    "        # Store the trained final model\n",
    "        self.final_trained_model = model\n",
    "\n",
    "        return self.final_trained_model\n",
    "\n",
    "    def voting_ensemble(self, X_train, y_train, X_val, y_val, n_select=3, voting='soft'):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using voting ensemble.\")\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=selected_models, voting=voting)\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"VotingClassifier\", voting_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return voting_clf\n",
    "\n",
    "    def stacking_ensemble(self, X_train, y_train, X_val, y_val, meta_model=None, n_select=3):\n",
    "        if not self.trained_models:\n",
    "            raise ValueError(\n",
    "                \"Please train models using `train()` before using stacking ensemble.\")\n",
    "\n",
    "        if meta_model is None:\n",
    "            meta_model = LogisticRegression(random_state=self.random_state)\n",
    "\n",
    "        # Ensure n_select does not exceed number of available models\n",
    "        n_select = min(n_select, len(self.best_model_name))\n",
    "        selected_models = [(name, self.trained_models[name])\n",
    "                           for name in self.best_model_name[:n_select]]\n",
    "\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=selected_models, final_estimator=meta_model)\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "        eval_metrics = self._evaluate_model(\n",
    "            \"StackingClassifier\", stacking_clf, X_val, y_val)\n",
    "        html_table = eval_metrics.to_html(index=False)\n",
    "        display(HTML(html_table))\n",
    "\n",
    "        return stacking_clf\n",
    "\n",
    "    def plot(self, model, X_val, y_val):\n",
    "        \"\"\"Plot confusion matrix, classification report, and ROC-AUC curve.\"\"\"\n",
    "\n",
    "        # Check if the model supports predict_proba (required for ROC-AUC)\n",
    "        supports_proba = hasattr(model, \"predict_proba\")\n",
    "\n",
    "        if self.use_gpu and isinstance(model, (cuLogisticRegression, cuKNeighborsClassifier, cuRandomForestClassifier, cuSVC)):\n",
    "            X_val_cudf = cudf.DataFrame.from_pandas(X_val)\n",
    "            y_val_cudf = cudf.Series(y_val)\n",
    "            y_pred = model.predict(X_val_cudf).to_numpy()\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val_cudf).to_numpy()\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            # For ROC-AUC, get the predicted probabilities if supported\n",
    "            if supports_proba:\n",
    "                y_proba = model.predict_proba(X_val)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Confusion Matrix for {model.__class__.__name__}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        # Classification Report\n",
    "        print(f'Classification Report for {model.__class__.__name__}:\\n')\n",
    "        print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "        # ROC-AUC Plot\n",
    "        if supports_proba:\n",
    "            # Check if it is a binary classification problem\n",
    "            if len(np.unique(y_val)) == 2:\n",
    "                fpr, tpr, _ = roc_curve(y_val, y_proba[:, 1])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                         label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'ROC Curve for {model.__class__.__name__}')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                # For multi-class classification, binarize the labels\n",
    "                y_val_bin = label_binarize(y_val, classes=np.unique(y_val))\n",
    "                n_classes = y_val_bin.shape[1]\n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "\n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(\n",
    "                        y_val_bin[:, i], y_proba[:, i])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "                # Plot ROC curve for each class\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                             label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(\n",
    "                    f'ROC Curve for {model.__class__.__name__} (multi-class)')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\n",
    "                f'ROC-AUC cannot be plotted for {model.__class__.__name__} as it does not support probability estimates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"logreg\": True,\n",
    "    \"knn\": True,\n",
    "    \"dt\": True,\n",
    "    \"rf\": True,\n",
    "    \"xgb\": True,\n",
    "    \"lgbm\": True,\n",
    "    \"catboost\": True,\n",
    "    \"support_vector\": True,\n",
    "}\n",
    "# Initialize modelling with GPU enabled\n",
    "modelling = Modelling(config=config, random_state=42, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model dan memilih 3 model terbaik\n",
    "modelling.train(X_train, y_train, X_val, y_val, metric='f1_score', n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Voting ensemble dengan n_select=5 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "voting_model = modelling.voting_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Stacking ensemble dengan n_select=4 (otomatis akan menggunakan hanya 3 model terbaik)\n",
    "stacking_model = modelling.stacking_ensemble(X_train, y_train, X_val, y_val, n_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation confussion matrix and classification report\n",
    "modelling.plot(modelling.best_model[0], X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = modelling.train_final(X_train, X_val, y_train, y_val)\n",
    "\n",
    "# prediction\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubes2-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
